2001-01-01 - News analysis	IA-32 execution layer (IA-32 EL) is a new technology that executes IA-32 applications on Intel Itanium processor family systems. Currently, support for IA-32 applications on Itanium-based platforms is achieved using hardware circuitry on the Itanium processors. This capability will be enhanced with IA-32 EL - software that will ship with Itanium-based operating systems and will convert IA-32 instructions into Itanium instructions via dynamic translation. In this paper, we describe aspects of the IA-32 execution layer technology, including the general two-phase translation architecture and the usage of a single translator for multiple operating systems. The paper provides details of some of the technical challenges such as precise exception, emulation of FP, MMX, and Intel streaming SIMD extension instructions, and misalignment handling. Finally, the paper presents some performance results.
2018-01-01 - Timing closure of clock enable signals on a 32 nm Intel Itanium processor	The next generation in the IntelÂ® ItaniumÂ® processor family, code named Poulson, has eight multi-threaded 64 bit cores. Poulson is socket compatible with the current IntelÂ® ItaniumÂ® Processor 9300 series (Tukwila). The new design integrates a ring-based system interface derived from portions of previous XeonÂ® and ItaniumÂ® processors, and includes 32MB of Last Level Cache (LLC). The processor is designed in IntelÂ®'s 32nm CMOS technology utilizing high-K dielectric metal gate transistors combined with nine layers of copper interconnect. The 18.2x29.9mm2 die contains 3.1 billion transistors, with 720 million allocated to the eight cores. A total of 54MB of on die cache is distributed throughout the core and system interface. Poulson implements twice as many cores as Tukwila while lowering the thermal design power (TDP) by 15Wto 170W and increases the top frequency of the I/O and memory inter faces by 50% to 6.4GT/s.
2005-01-01 - Practical Compiler Techniques on Efficient Multithreaded Code Generation for OpenMP Programs	An ItaniumÂ® processor implemented in 32 nm CMOS with nine layers of Cu contains 3.1 billion transistors. The die measures 18.2 mm by 29.9 mm. The processor has eight multi-threaded cores, a ring based system interface and combined cache on the die is 50 MB. High-speed links allow for peak processor-to-processor bandwidth of up to 128 GB/s and memory bandwidth of up to 45 GB/s.
2011-01-01 - Data Cache Prefetching With Dynamic Adaptation	The third-generation Itanium processor targets the high-performance server and workstation market. To do so, the design team sought to provide higher performance through increased frequency and a larger L3 cache. At the same time, we had to limit the power dissipation to fit into the existing platform envelope. These considerations led to what we now call the Itanium 2 processor 6M: the latest generation of Itanium 2, which features a 6-Mbyte, 24-way set-associative on-die L3 cache. The design implements a 2-bundle 64-bit explicitly parallel instruction computing (EPIC) architecture and is fully compatible with previous implementations. Although this processors frequency is 50 percent higher than that of the previous generation, the maximum power dissipation holds flat at 130 W to ensure the platform's backward compatibility.
2017-01-01 - VD-IT2, Virtual Disk Cloning on Disk Arrays Using a Type-2 Fuzzy Controller	The second member in the Itanium Processor Family, the Itanium 2 processor, was designed to meet the challenge for high performance in today's technical and commercial server applications. The Itanium 2 processor's data cache microarchitecture provides abundant memory resources, low memory latencies and cache organizations tuned to for a variety of applications. The data cache design provides four memory ports to support the many performance optimizations available in the EPIC (Explicitly Parallel Instruction Computing) design concepts, such as predication, speculation and explicit prefetching. The three-level cache hierarchy provides a 16KB 1-cycle first level cache to support the moderate bandwidths needed by integer applications. The second level cache is 256KB with a relatively low latency and FP balanced bandwidth to support technical applications. The onchip third level cache is 3MB and is designed to provide the low latency and the large size needed by commercial and technical applications.
2006-01-01 - Prematerialization: Reducing register pressure for free	EPIC (explicitly parallel instruction computing) architectures, exemplified by the Intel Itanium, support a number of advanced architectural features, such as explicit instruction-level parallelism, instruction predication, and speculative loads from memory. However, compiler optimizations that take advantage of these features can profoundly restructure the program's code, making it potentially difficult to reconstruct the original program logic from an optimized Itanium executable. This paper describes techniques to undo some of the effects of such optimizations and thereby improve the quality of reverse engineering such executables.
2006-01-01 - Whole-program optimization of global variable layout	The clock generation and distribution system for the 130-nm Itanium 2 processor operates at 1.5 GHz with a skew of 24 ps. The Itanium 2 processor features 6 MB of on-die L3 cache and has a die size of 374 mm/sup 2/. Fuse-based clock de-skew enables post-silicon clock optimization to gain higher frequency. This paper describes the clock generation, global clock distribution, local clocking, and the clock skew optimization feature.
2011-01-01 - Poulson: An 8 core 32 nm next generation IntelÂ® ItaniumÂ® processor	The Itanium processor cartridge is a packaging optimization for electrical and thermal performance in a server environment. The 3-in. x 5-in. cartridge contains the Itanium CPU, up to 4 megabytes of level-3 (L3) cache, an innovative power delivery scheme, and an integrated vapor chamber thermal spreading lid for removing power. Cartridges and a chip set can be ganged electrically by means of a glueless bidirectional, multidrop system bus. Power is delivered through a custom connection with separate voltages for the 0.18-micron CPU and 0.25-micron custom cache devices. An I/sup 2/C serial connection provides access to system management features such as temperature monitoring and cartridge identification information.
2008-01-01 - Tukwila - a quad-core IntelÂ® ItaniumÂ® processor	Discusses the thermal, mechanical, and electrical requirements and design solutions for the Itanium/spl reg/ processor cartridge. High power dissipation level of the cartridge, with up to five active dice, poses significant thermal design challenges. The thermal solution employed is presented and the design of heat pipe lid and effectiveness of the thermal interface material is discussed. The thermal behavior of the cartridge is analyzed using numerical analysis and experimental validations. The mechanical section discusses the pieces of the cartridge enclosure designed to ensure proper bond line thickness (BLT) of the thermal interface between the die and the heat pipe lid pedestals, engagement of the cartridge with enabling components, and protection against shock and vibration under various environmental conditions. Demanding power requirements by the Itanium/spl reg/ processor cartridge and the high-speed buses used for communication between the CPU and other components resulted in challenging package and substrate design. High-speed layout techniques were employed to meet the electrical performance requirements.
2002-01-01 - Peppermint and Sled: tools for evaluating SMP systems based on IA-64 (IPF) processors	Clock distribution on the 90 nm Itanium/spl reg/ processor, code-named Montecito, is detailed. A region-based active de-skew system reduces the PVT sources of skew across the entire die during normal operation. Clock vernier devices inserted at each local clock buffer allow up to a 10% clock-cycle adjustment via firmware or scan. The system supports a constantly varying frequency and consumes <25 W from the PLL to latch while providing <10 ps of skew across PVT.
2014-01-01 - Using ECC Feedback to Guide Voltage Speculation in Low-Voltage Processors	The next generation in the Itanium/spl reg/ processor family, code named Montecito, is introduced. Implemented in a 90nm 7M process, the processor has two dual-threaded cores integrated with 26.5MB of cache. Of the total of 1.72B transistors, 64M are dedicated to logic and the rest to cache. With both cores operating at full speed, the chip consumes 100W.
2014-01-01 - A General Model Checking Framework for Various Memory Consistency Models	This paper describes the embedded feedback and control system on a 90 nm Itanium/spl reg/-family processor, code-named Montecito, that maximizes performance while staying within a target power and temperature (PT) envelope. This system utilizes on-chip sensors and an embedded micro-controller to measure PT and modulate voltage and frequency to meet PT constraints.
2012-01-01 - SMARQ: Software-Managed Alias Register Queue for Dynamic Optimizations	The six-issue integer datapath of the second-generation Itanium microprocessor is described. Pulse techniques enable a high-speed, 20-ported, 128-entry, 65 bit register file with only 12 wordlines per register. A four-stage operand bypass network achieves a fully bypassed design with operands sourced from 34 locations with 16 destinations. To control this network, over 280 bypass comparators are utilized. Using half a clock for execution and half a clock for bypass, each result is available for the next instruction. Functional units are pre-enabled, reducing power consumption by 15% while eliminating a stage of result mixing and improving performance. The part is fabricated in a six-layer 0.18 /spl mu/m process and operates at 1.0 GHz at 1.5 V, consuming less than 130 W in about 420 mm/sup 2/.
2012-01-01 - Hardware Counters Based Analysis of Memory Accesses in SMPs	The 3-MB on-chip level three cache in the Itanium 2 processor, built on an 0.18-/spl mu/m, six-layer Al metal process, employs a subarray design style that efficiently utilizes available area and flexibly adapts to floor plan changes. Through a distributed decoding scheme and compact circuit design and layout, 85% array efficiency was achieved for the subarrays. In addition, various test and reliability features were included. The cache allows for a store and a load every four core cycles and has been characterized to operate above 1.2 GHz at 1.5 V and 110/spl deg/C. When running at 1.0 GHz, the cache provides a total bandwidth of 64 GB/s.
2011-01-01 - Test access and the testability features of the Poulson multi-core Intel ItaniumÂ® processor	The next generation in the Itanium processor family is introduced. The processor has 4 dual-threaded cores integrated on die with a system interface and 30MB of cache in an 8M 65nm process. The 21.5times32.5mm2 die contains 2.05 billion transistors. The silicon is designed to operate the cores up to 2.0GHz and the system interface at 2.4GHz, with a thermal design power (TDP) of 170W at 110degC.
2011-01-01 - Hardware hooks for transition scan characterization	The 24MB level-3 cache on a dual-core Itanium/spl reg/ processor has more than 1.47G transistors. The cache uses an asynchronous design to reduce latency and power, and it includes other power saving and reliability improvement features. The 5-cycle array operates above 2GHz at 0.8V and 85/spl deg/C while consuming less than 4.2W.
2012-01-01 - A 32 nm, 3.1 Billion Transistor, 12 Wide Issue ItaniumÂ® Processor for Mission-Critical Servers	The700mm2 65nm Itaniumreg processor codenamed Tukwila integrates four cores and a system interface with six QuickPathreg interconnect channels and four memory interconnect channels. The large die and high level of integration coupled with process variability present clock-system design challenges in the areas of power consumption and variability compensation that discuss in this paper. The clock system, which is a cascaded-PLL architecture with an initial filter PLL that receives a 133 MHz reference clock. This maiden PLL filters reference-clock jitter and outputs a 133 MHz clock to 13 downstream PLLs. Each downstream PLL has a duty-cycle corrector that monitors and corrects the end-of-route duty cycle.
2011-01-01 - Variation tolerant digitally assisted high-speed IO PHY	The next generation in the Itanium/spl reg/ processor family, code named Montecito is introduced. The processor has two dual-threaded cores integrated on die with 26.5MB of cache in a 90nm process with 7 layers of copper interconnect. The die is 21.5mm by 27.7mm and includes 1.72 billion transistors. With both cores at full frequency it consumes 100W. The micro-architecture and circuit methodologies are leveraged from the prior Itanium2 processors (E. Fetzer et al., 2005). Improvements include the integration of 2 cores on-die, each with a dedicated 12MB 3rd level cache, a 1MB 2nd level I cache and dual-threading. Susceptibility to soft errors is also reduced and power efficiency improved through low power techniques and active power management.
2011-01-01 - A 32nm 3.1 billion transistor 12-wide-issue ItaniumÂ® processor for mission-critical servers	This 130nm Itanium/spl reg/ 2 processor implements the Explicitly Parallel Instruction Computing (EPIC) architecture and features an on-die 6MB, 24-way set associative L3 cache. The 374mm/sup 2/ die contains 410M transistors and is implemented in a dual-Vt process with 6 layers copper interconnect and FSG dielectric. The processor runs at 1.5GHz at 1.3V and dissipates a maximum of 130W. This paper reviews circuit design and package details, power delivery, RAS, DFT and DFM features, as well as an overview of the design and verification methodology. The fuse-based clock de-skew circuit achieves 24ps skew across the entire die, while the scan-based skew control further reduces it to 7ps. The 128-bit front-side bus supports up to 4 processors on a single bus with a bandwidth of up to 6.4GB/s.
2009-01-01 - Enabling High-Productivity SIP Application Development: Modeling and Simulation of Superconducting Quantum Interference Filters	The clock generation and distribution system for the third generation Itanium/spl reg/ processor operates at 1.5 GHz with a skew of 24 ps. Clock optimization fuses enable post-silicon speed path balancing for higher performance.
2010-01-01 - Lessons from at-speed scan deployment on an IntelÂ® ItaniumÂ® microprocessor	The authors present the 64 bit Itanium/spl trade/ microprocessor, which incorporates over 220M transistors on a 465 mm/sup 2/ die and operates at >1.2 GHz with an 8-stage pipeline in a 0.18 /spl mu/m process. It has three levels of on-chip cache totaling over 3.3 MB providing >32 GB/s bandwidth at each level.
2010-01-01 - Synthesis of a unified unit for evaluating an application-specific set of elementary functions	A third-generation 1.5 GHz Itanium/spl reg/ processor implements the Explicitly Parallel Instruction Computing (EPIC) architecture and features an on-die 6 MB, 24-way set associative L3 cache. The 374 mm/sup 2/ die contains 410M transistors and is implemented in a dual-V/sub T/ 0.13 /spl mu/m technology having 6-level Cu interconnects with FSG dielectric and dissipates 130 W.
2011-01-01 - Exact and Approximated Error of the FMA	The 18-way set-associative, single-ported 9 MB cache for the Itanium 2 processor uses 210 identical 48-kB sub-arrays with a 2.21-/spl mu/m/sup 2/ cell in a 130-nm 6-metal technology. The processor runs at 1.7 GHz at 1.35 V and dissipates 130 W. The 432-mm/sup 2/ die contains 592 M transistors, the largest transistor count reported for a microprocessor. This paper reviews circuit design and implementation details for the L3 cache data and tag arrays. The staged mode ECC scheme avoids a latency increase in the L3 tag. A high V/sub t/ implant improves the read stability and reduces the sub-threshold leakage.
2010-01-01 - Extending the Monte Carlo Processor Modeling Technique: Statistical Performance Models of the Niagara 2 Processor	Provides a simple formal model for Itanium/sup TM/ shared memory consistency covering a core set of instructions, that is reverse-engineered from <http://developer.intel.com/design/ia-64/downloads/24531802.htm> and <http://www.cs.utah.edu/mpv/papers/neiger/fmcad2001.pdf>. Our model sheds light on tricky concepts such as causality. It deals with cacheable memory instructions consisting of acquire loads, ordinary loads, release stores and ordinary stores, as well as memory fences. It does not currently handle atomic read-modify-writes, non-cacheable memory or special rules pertaining to data dependencies involving registers. Despite its simplicity, our model captures all published ordering properties of the instructions we consider. While operational models have been proposed for commercial shared memory systems (notably for Sparc V9), a notable feature of our operational model is its use of a few explicit devices such as vector timestamps to clearly describe the tricky notion of causality.
2010-01-01 - IntelÂ® QuickPath Interconnect Architectural Features Supporting Scalable System Architectures	This paper describes the second level 256 kB unified cache incorporated into the next generation of the Itanium/spl trade/ processor family code named McKinley. The paper describes the datapath structures that provide a non-blocking, out-of-order interface to the processor core achieving a minimum 5-cycle latency with a standalone bandwidth of 72 GB/s.
2010-01-01 - Software-Implemented Fault Injection at Firmware Level	In order to achieve high instruction level parallelism (ILP), designers are turning to very long instruction word (VLIW) based designs, in which different types of instructions are grouped together as bundles of 128 bits or longer. In VLIW, the added nops increase the code size, limit processor performance by the under-utilization of functional units. In examining these performance issues of VLIW systems, we consider Intel first 64-bit architecture, the IA-64, and its first implementation, the Itanium, which employs Intel version of VLIW. We present a comprehensive analysis of the problem of under-utilization due to nops and stops across a wide range of application domains through the use of three different benchmark suites: SPEC CPU 2000, MediaBench, and PacketBench. Our results show that, on average, nops create an under-utilization factor of 28.46% in the case of SPEC CPU, 32.27% in MediaBench, and 29.76% in PacketBench. We also analyze the characteristics of different instruction bundle formats, which we obtain by collecting statistics concerning the frequency of the bundle formats
2010-01-01 - Newton-Raphson algorithms for floating-point division using an FMA	Presents a collection of slides covering the following topics: 8-socket topology; Poulson core; Itanium; instruction level parallelism; memory parallelism; thread parallelism; multicore parallelism; multisocket parallelism; reliability, fault tolerance and recoverability; power aware design; Poulson status.
2005-01-01 - Building applications for the Linux Standard Base	We describe our memory performance analysis of SPEC2000C using the newly released Intel(R) Itanium/sup TM/ processor (IPF). Memory overhead is very significant for SPEC200OC; on the average 39% cycles are spent in data stalls. Cache misses are significant, but also data translation performance (DTLB) affects many benchmarks. We present a study based on collecting measurements from the hardware performance counters and cache profiling using program instrumentation of loads/stores. We define important loads as the load sites that contribute at least 95% of the cache misses at all levels. Our measurements show that the number of important loads in a program is relatively small. Our analysis show that important loads are most of the time contained in inner loops, and that the trip counts of these loops is significantly high. We present preliminary results on using stride profiling to reduce cache misses of important loads, bringing an average of 6% improvement to SPEC2000C. Finally, we present our study of data translation performance and propose design choices.
2010-01-01 - A method for debugging of pipelined processors in formal verification by Correspondence Checking	This paper presents the design of the Itanium/sup TM/ Processors system bus interface achieving a peak data bandwidth of 2.1 GB/s in a glueless four-way multiprocessing system. A source-synchronous data bus with differential strobes enables this high bandwidth. Topics covered in this paper include optimization technique for the system topology, CPU package, signaling protocol, and I/O circuits. Highly accurate modeling and validation methodologies enable a good correlation of experimental results with simulation data.
2009-01-01 - Reconfigurable sparse/dense matrix-vector multiplier	The 18-way set-associative, single-ported 9 MB cache for the Itanium/spl reg/2 processor, presented in this paper, uses 210 identical 48 kB sub-arrays with a 2.21 /spl mu/m/sup 2/ cell in a 0.13 /spl mu/m 6M CMOS technology. A staged mode ECC scheme avoids a latency increase in the L3 tag. A high Vt implant improves the read stability and reduces the sub-threshold leakage.
2009-01-01 - Control flow obfuscation with information flow tracking	Unlike past semiconductor manufacturing processes, nanometer technology has seen an exponential growth of complex design rules and constraints. As a result, direct optical shrink of products between process nodes is becoming less feasible. To facilitate aggressive time-to-market requirements by re-using designs under new process technology, new CAD automation tools and methodologies have been developed. This paper describes a process shifting flow of 130nm custom layout to 90nm. Design challenges at the new process will first be overviewed, followed by EDA-assisted layout migration. Finally, productivity gains together with the design qualities will be shown on the implementation of a next generation Itanium@2 server chip.
2009-01-01 - Development of polyaniline nanocomposite thin film micro-gas sensor array for the qualitative analysis of inorganic vapor	With modern high speed circuit design using state of the art automated place and route (APR) flows, synthesis of clock enable (CE) signals is becoming increasingly difficult in terms of timing closure. The size of APR blocks in digital physical design in microprocessor projects is expanding with every generation of microprocessors as the implementation tools become more capable of handling large designs with high quality results and fast turnaround times. However, larger APR blocks make CE synthesis progressively difficult as timing closure complexity on these signals increases dramatically. The main problem is due to a single CE register driving the signal to a relatively larger area of the design, and to a greater number of clock gating cells. In this paper, we present automated duplication of CE logic in the APR flow to achieve timing closure on a 32 nm Intel Itanium project. We show how timing convergence is achieved without any additional effort from the physical designers, and with no changes required in the RTL. Solutions to the CE problem with smaller degree of automation and more manual effort, which were used on our previous projects, are also discussed and compared, and the reasons they are deemed inadequate are explained.
2009-01-01 - Advancing Moore's law: Challenges and opportunities	This paper presents the design of the ItaniumTMProcessor's system bus interface achieving a peak data bandwidth of 2.1GB/s in a glue-less 4-way multiprocessing system. A source-synchronous data bus with differential strobes enables this high bandwidth. Topics covered in this paper include optimisation technique for the system topology, CPU package, signalling protocol and I/O circuits. Highly accurate modelling and validation methodologies enable a good correlation of experimental results with simulation data.
2009-01-01 - 3-D Brain MRI Tissue Classification on FPGAs	A 16 kB four-ported physically addressed cache to be placed on a 64 b Itanium microprocessor operates at 1.2 GHz with 19.2 GB/s peak bandwidth. Circuit and microarchitectural techniques are optimized to allow a single-cycle read access latency. The cache occupies 3.2Ã—1.8 mm/sup 2/ in a 0.18 Î¼m CMOS process.
2009-01-01 - Dynamic frequency-switching clock system on a quad-core ItaniumÂ® processor	This paper describes a just-in-time (JIT) Java compiler for the Intel/spl reg/ Itanium/spl reg/ processor. The Itanium processor is an example of an Explicitly Parallel Instruction Computing (EPIC) architecture and thus relies on aggressive and expensive compiler optimizations for performance. Static compilers for Itanium use aggressive global scheduling algorithms to extract instruction-level parallelism. In a JIT compiler, however, the additional overhead of such expensive optimizations may offset any gains from the improved code. In this paper, we describe lightweight code generation techniques for generating efficient Itanium code. Our compiler relies on two basic methods to generate efficient code. First, the compiler uses inexpensive scheduling heuristics to model the Itanium microarchitecture. Second, the compiler uses the semantics of the Java virtual machine to extract instruction-level parallelism.
2009-01-01 - A Practical Approach to Hardware Performance Monitoring Based Dynamic Optimizations in a Production JVM
2008-01-01 - A 65nm 2-Billion-Transistor Quad-Core ItaniumÂ® Processor	The 700mm2 65nm Itaniumreg processor doubles the number of cores over its predecessor, from 2 to 4. It also adds a system interface that is roughly as large as two cores, including six QuickPath interconnects and four FBDIMM channels. This 3x increase in logic circuits per socket presents two major circuit challenges that are addressed in this paper.
2008-01-01 - Circuit Design for Voltage Scaling and SER Immunity on a Quad-Core ItaniumÂ® Processor
2009-01-01 - A 65 nm 2-Billion Transistor Quad-Core Itanium Processor	A PLL generates a high-frequency core clock for a 1GHz processor by multiplying up the system clock. The clock is distributed across the 19/spl times/14 mm/sup 2/ core via a shielded, balanced, H-tree to the final pulsed gated buffers with <62 ps measured skew. Test features include phase shrinking and regional skew manipulation.
2008-01-01 - Bayesian Phylogenetic Inference in the LIBI Grid Platform: A Tool to Explore Large Data Sets	A clock-generation system delivers fixed- and variable-frequency clocks for adaptive power control on a 1.7 B-transistor dual-core CPU. Frequency synthesizers digitally divide a fixed-frequency PLL clock in 1/64th cycle steps using programmable voltage-frequency-converter loops. 1-cycle loop response tracks supply transients with adaptive modulation, improving CPU performance by over 10% compared to a fixed-frequency design.
2008-01-01 - Configurable Flow Models for FPGA Particle Graphics Engines
2009-01-01 - FPC: A High-Speed Compressor for Double-Precision Floating-Point Data	The dual-thread 18-port 128w/spl times/82b FPU register file, and the 22-port 128w/spl times/65b integer register file of the microprocessor is described. Parity embedded into each register provides soft error detection. The design integrates a charge-compensated thread switch and power-saving features to operate at 1.1V consuming 400mW at maximum frequency.
2006-01-01 - Analysis and Characterization of Intel Itanium Instruction Bundles for Improving VLIW Processor Performance	This 3 MB on-chip level-three cache employs subarray design style, and achieves 85% array efficiency. Characterized to operate up to 1.2 GHz, the cache allows a store and a load in every four core cycles, and provides a total bandwidth of 64 GB/s at 1.0 GHz.
2008-01-01 - Efficient sorting algorithms for the cell broadband engine
2008-01-01 - Pre-virtualization: Soft layering for virtual machines	A 6-issue integer datapath with a 20-ported 128/spl times/65 bit register file in a 0.18 /spl mu/m process operates up to 1.2 GHz at 1.5 V. Operands bypass through 4 stages, from 34 locations, using 1/2 clock for execution and 1/2 clock for bypass. Each result is available for the next instruction.
2008-01-01 - From Speculation to Security: Practical and Efficient Information Flow Tracking Using Speculative Hardware
2008-01-01 - Open64 compiler infrastructure for emerging multicore/manycore architecture All Symposium Tutorial
2008-01-01 - Performance evaluation of NSF application benchmarks on parallel systems	Clock distribution on the microprocessor codenamed Montecito features four distinct segments and topologies each tuned to a specific purpose. A region based active de-skew (RAD) system reduces the process, voltage, and temperature sources of skew across the 21.5 /spl times/ 27.7mm/sup 2/ die during normal operation. Clock vernier devices (CVDs) inserted at each local clock buffer allows 70ps of adjustment via scan. The system supports a constantly varying frequency and consumes less than 25W on its 30mm route from PLL to latch.
2008-01-01 - Lattice Boltzmann simulation optimization on leading multicore platforms
2008-01-01 - A hash-TLB approach for MMU virtualization in xen/IA64	This article consists of a collection of slides from the author's conference presentation. Some of the topics discussed include: Tukwila Overview; Exploiting Thread Level Parallelism; Improving Instruction Level Parallelism; Scalability and Headroom; Power and Frequency Management; and Enterprise RAS and Manageability.
2008-01-01 - Reconstructing Control Flow in Modulo Scheduled Loops
2008-01-01 - Scientific Computing Applications on a Stream Processor	The Intel/spl reg/ Itanium/spl reg/ architecture contains a number of innovative compiler-controllable features designed to exploit instruction level parallelism. New code generation and optimization techniques are critical to the application of these features to improve processor performance. For instance, the Itanium/spl reg/ architecture provides a compiler-controllable virtual register stack to reduce the penalty of memory accesses associated with procedure calls. The Itanium/spl reg/ Register Stack Engine (RSE) transparently manages the register stack and saves and restores physical registers to and from memory as needed. Existing code generation techniques for the register stack aggressively allocate virtual registers without regard to the register pressure on different control-flow paths. As such, applications with large data sets may stress the RSE, and cause substantial execution delays due to the high number of register saves and restores. Since the Itanium/spl reg/ architecture is developed around Explicitly Parallel Instruction Computing (EPIC) concepts, solutions to increasing the register stack efficiency favor code generation techniques rather than hardware approaches.
2008-01-01 - MV-FT: Efficient Implementation for Matrix-Vector Multiplication on FT64 Stream Processor	Detailed modeling of the performance of commercial applications is difficult. The applications can take a very long time to run on real hardware and it is impractical to simulate them to completion on performance models. Furthermore, these applications have complex execution environments that cannot easily be reproduced on a simulator, making porting the applications to simulators difficult. We attack these problems using the well-known SimPoint methodology to find representative portions of an application to simulate, and a dynamic instrumentation framework called Pin to avoid porting altogether. Our system uses dynamic instrumentation instead of simulation to find representative portions - called Pin-Points - for simulation. We have developed a toolkit that automatically detects PinPoints, validates whether they are representative using hardware performance counters, and generates traces for large ItaniumÂ® programs. We compared SimPoint-based selection to random selection of simulation points. We found for 95% of the SPEC2000 programs we tested, the PinPoints prediction was within 8% of the actual whole-program CPI, as opposed to 18% for random selection. We measure the end-to-end error, comparing real hardware to a performance model, and have a simple and efficient methodology to determine the step that introduced the error. Finally, we evaluate the system in the context of multiple configurations of real hardware, commercial applications, and industrial-strength performance models to understand the behavior of a complete and practical workload collection system. We have successfully used our system with many commercial ItaniumÂ® programs, some running for trillions of instructions, and have used the resulting traces for predicting performance of those applications on future Itanium processors.
2007-01-01 - Computational Science IDE for HPCMP Systems	The Itanium 2 processor extends the processing power of the Itanium processor family with a capable and balanced microarchitecture. Executing up to six instructions at a time, it provides both performance and binary compatibility for Itanium-based applications and operating systems.
2007-01-01 - Evaluation of a High-Level-Language Methodology for High-Performance Reconfigurable Computers	The performance of in-order execution Itanium/sup TM/ processors can suffer significantly due to cache misses. Two memory latency tolerance approaches can be applied for the Itanium processors. One uses an out-of-order (OOO) execution core; the other assumes multithreading support and exploits cache prefetching via speculative precomputation (SP). This paper evaluates and contrasts these two approaches. In addition, this paper assesses the effectiveness of combining the two approaches. For a select set of memory-intensive programs, an in-order SMT Itanium processor using speculative precomputation can achieve performance improvement (92%) comparable to that of an out-of-order design (87%). Applying both 000 and SP yields a total performance improvement of 141% over the baseline in-order machine. OOO tends to be effective in prefetching-for L1 misses; whereas SP is primarily good at covering L2 and L3 misses. Our analysis indicates that the two approaches can be redundant or complementary depending on the type of delinquent loads that each targets. Both approaches are effective on delinquent loads in the loop body; however only SP is effective on delinquent loads found in loop control code.
2007-01-01 - Implementation and Evaluation of Matrix-matrix Multiplication on FT64 Stream Processor	The 64-bit IntelÂ® Itaniumâ„¢ architecture is designed for high-performance scientific and enterprise computing, and the Itanium processor is itsfirst silicon implementation. Features such as extensive arithmetic support, predication, speculation, and explicit parallelism can be used to provide a sound infrastructure for supercomputing. A largenumber of high-performance computer companies are offering Itaniumâ„¢-based systems, some capable of peak performance exceeding 50 GFLOPS. In this paper we give an overview of the most relevant architectural features and provide illustrations of how these features are used in both low-level and high-level support for scientific and engineering computing, including transcendental functions and linear algebra kernels.
2008-01-01 - Correctly Rounded Multiplication by Arbitrary Precision Constants	In this paper, performance characteristics of the Itanium/sup TM/ processor, the first implementation of the Itanium/sup TM/ Processor Family (IPF), is examined for the task of data encryption using public key and symmetric key encryption algorithms. The Itanium/sup TM/ processor key performance characteristics: wide issue width, large number of functional units, and large number of registers are examined for the task of performing multi-precision arithmetic dominant in public key algorithms and the computing requirements of symmetric key encryption algorithms.
2007-01-01 - Propagation of UWB Pulses on Metal Strips Printed on Semiconductor Dielectrics	Intel's Montecito is the first Itanium processor to feature duplicate, dual-thread cores and cache hierarchies on a single die. It features a landmark 1.72 billion transistors and server-focused technologies, and it requires only 100 watts of power. Intel's Itanium 2 processor series has regularly delivered additional performance through the increased frequency and cache as evidenced by the 6-Mbyte and 9-Mbyte versions.
2007-01-01 - Solution of large complex problems in computational electromagnetics using higher order basis in MOM with parallel solvers	The Intel Itanium architecture uses a dedicated 32-entry hardware table, the advanced load address table (ALAT) to support data speculation via an instruction set interface. This study presents an empirical evaluation of the use of the ALAT and data speculative instructions for several optimizing compilers. We determined what and how often compilers generated the different speculative instructions, and used the Itanium's hardware performance counters to evaluate their run-time behavior. We also performed a limit study by modifying one compiler to always generate data speculation when possible. We found that this aggressive approach significantly increased the amount of data speculation and often resulted in performance improvements, of as much as 10% in one case. Since it worsened performance only for one application and then only for some inputs, we conclude that more aggressive data speculation heuristics than those employed by current compilers are desirable and may further improve performance gains from data speculation.
2007-01-01 - A cross-platform parallel MoM code with ScaLAPACK solver	This paper describes scheduling optimizations in the Intel/spl reg/ Itanium/spl reg/ compiler to prevent cache penalties due to various micro-architectural effects on the Itanium 2 processor. This paper does not try to improve cache hit rates but to avoid penalties, which probably all processors have in one form or another, even in the case of cache hits. These optimizations make use of sophisticated methods for disambiguation of memory references, and this paper examines the performance improvement obtained by integrating these methods into the cache optimizations.
2007-01-01 - Transient analysis of the human body with a mobile phone subject to intense UWB pulses	This paper discusses a repertoire of well-known and new compiler optimizations that help produce excellent server application performance and investigates their performance contributions. These optimizations combined produce a 40% speed-up in on-line transaction processing (OLTP) performance and have been implemented in the Intel C/C++ Itanium compiler. In particular, the paper presents compiler optimizations that take advantage of the Itanium register stack, proposes an enhanced Linux preemption model and demonstrates their performance potential for server applications.
2007-01-01 - Performance Evaluation of the Dual-Core Based SGI Altix 4700	This paper examines the efficiency of the register stack engine (RSE) in the canonical Itanium architecture, and introduces novel optimization techniques to enhance the RSE performance. To minimize spills and fills of the physical register file, optimizations are applied to reduce internal fragmentation in statically allocated register stack frames. Through the use of dynamic register usage (DRU) and dead register value information (DVI), the processor can dynamically guide allocation and deallocation of register frames. Consequently, a speculatively allocated register frame with a dynamically determined frame size can be much smaller than the statically determined frame size, thus achieving minimum spills and fills. Using the register stack engine (RSE) in the canonical Itanium architecture as the baseline reference, we thoroughly study and gauge the tradeoffs of the RSE and the proposed optimizations using a set of SPEC CPU2000 benchmarks built with different compiler optimizations. A combination of frame allocation policies using the most frequent frame size and deallocation policies using dead register information proves to be highly effective. On average, a 71% reduction in aggregate spills and fills can be achieved over the baseline reference.
2007-01-01 - Leveraging Predicated Execution for Multimedia Processing	In this paper, we describe an effort to prototype an Itanium microarchitecture using an FPGA. The microarchitecture model is written in the Bluespec hardware description language (HDL) and supports a subset of the Itanium instruction set architecture. The microarchitecture model includes details such as multi-bundle instruction fetch, decode and issue; parallel pipelined execution units with scoreboarding and predicated bypassing; and multiple levels of cache hierarchies. The microarchitecture model is synthesized and prototyped on a special FPGA card that allows the processor model to interface directly to the memory bus of a host PC. This is an effort toward developing a flexible microprocessor prototyping framework for rapid design exploration.
2007-01-01 - COBRA: An Adaptive Runtime Binary Optimization Framework for Multithreaded Applications	This paper describes the embedded feedback and control system on a 90-nm Itanium family processor, code-named Montecito, that maximizes performance while staying within a target power and temperature (PT) envelope. This system, referred to as Foxton Technology (FT), utilizes on-chip sensors and an embedded microcontroller to measure PT and modulate both voltage and frequency (VF) to optimize performance while meeting PT constraints. Changing both VF takes advantage of the cubic relationship of P/spl prop/CV/sup 2/F. We present measured results that show a 31% reduction in power for only a 10% drop in frequency. Montecito is able to implement FT using only 0.5% of the die area and 0.5% of the die power.
2007-01-01 - Compiler Optimizations for Fault Tolerance Software Checking	This 64-b microprocessor is the second-generation design of the new Itanium architecture, termed explicitly parallel instruction computing (EPIC). The design seeks to extract maximum performance from EPIC by optimizing the memory system and execution resources for a combination of high bandwidth and low latency. This is achieved by tightly coupling microarchitecture choices to innovative circuit designs and the capabilities of the transistors and wires in the 0.18-/spl mu/m bulk Al metal process. The key features of this design are: a short eight-stage pipeline, 11 sustainable issue ports (six integer, four floating point, half-cycle access level-1 caches, 64-GB/s level-2 cache and 3-MB level-3 cache), all integrated on a 421 mm/sup 2/ die. The chip operates at over 1 GHz and is built on significant advances in CMOS circuits and methodologies. After providing an overview of the processor microarchitecture and design, this paper describes a few of these key enabling circuits and design techniques.
2007-01-01 - News Briefs	The Itanium processor is the first implementation of the IA-64 instruction set architecture (ISA). The design team optimized the processor to meet a wide range of requirements: high performance on Internet servers and workstations, support for 64-bit addressing, reliability for mission-critical applications, full IA-32 instruction set compatibility in hardware, and scalability across a range of operating systems and platforms. The processor employs EPIC (explicitly parallel instruction computing) design concepts for a tighter coupling between hardware and software. In this design style the hardware-software interface lets the software exploit all available compilation time information and efficiently deliver this information to the hardware. It addresses several fundamental performance bottlenecks in modern computers, such as memory latency, memory address disambiguation, and control flow dependencies.
2007-01-01 - Developing a Computational Science IDE for HPC Systems	An Itanium Architecture microprocessor in 90-nm CMOS with 1.7B transistors implements a dynamically-variable-frequency clock system. Variable frequency clocks support a power management scheme which maximizes processor performance within a configured power envelope. Core supply voltage and clock frequency are modulated dynamically in order to remain within the power envelope. The Foxton controller and dynamically-variable clock system reside on die while the variable voltage regulator and power measurement resistors reside off chip. In addition, high-bandwidth frequency adjustment allows the clock period to adapt during on-die supply transients, allowing higher frequency processor operation during transients than possible with a single-frequency clock system.
2005-01-01 - Near Overhead-free Heterogeneous Thread-migration	This paper describes an Itanium processor implemented in 65 nm process with 8 layers of Cu interconnect. The 21.5 mm by 32.5 mm die has 2.05B transistors. The processor has four dual-threaded cores, 30 MB of cache, and a system interface that operates at 2.4 GHz at 105degC . High speed serial interconnects allow for peak processor-to-processor bandwidth of 96 GB/s and peak memory bandwidth of 34 GB/s.
2007-01-01 - Loop Optimization using Hierarchical Compilation and Kernel Decomposition	This 130-nm Itanium 2 processor implements the explicitly parallel instruction computing (EPIC) architecture and features an on-die 6-MB 24-way set-associative level-3 cache. The 374-mm2 die contains 410 M transistors and is implemented in a dual-V/sub t/ process with six Cu interconnect layers and FSG dielectric. The processor runs at 1.5 GHz at 1.3 V and dissipates a maximum of 130 W. This paper reviews circuit design and package details, power delivery, the reliability, availability, and serviceability (RAS) features, design for test (DFT), and design for manufacturability (DFM) features, as well as an overview of the design and verification methodology. The fuse-based clock deskew circuit achieves 24-ps skew across the entire die, while the scan-based skew control further reduces it to 7 ps. The 128-bit front-side bus has a bandwidth of 6.4 GB/s and supports up to four processors on a single bus.
2006-01-01 - Predicate removing technique in machine emulation for IA-64 aechitecture	The integer and floating-point register files of the 90-nm generation Itanium Microprocessor are described. A pulsed, shared word line technique enables a 22 ported integer array with only 12 word lines per register. An in-register ripple parity system provides soft error detection with no impact to operand bypass or pipeline depth while keeping consuming less that 6% of the total register datapath area. The register file implements temporal multi-threading by multiplexing the read and write ports to two storage nodes enabling registers to write both foreground and background threads to the same register at the same time. Thread switching completes in one cycle. The register files are fabricated in a 7-layer 90-nm process and operate up to 2.0 GHz while consuming 400 mW per register array.
2007-01-01 - Future Fab	Exploiting Thread-Level Parallelism (TLP) is a promising way to improve the performance of applications with the advent of general-purpose cost effective uni-processor and shared-memory multiprocessor systems. In this paper, we describe the OpenMP* implementation in the Intel/spl reg/ C++ and Fortran compilers for Intel platforms. We present our major design consideration and decisions in the Intel compiler for generating efficient multithreaded codes guided by OpenMP directives and pragmas. We describe several transformation phases in the compiler for the OpenMP* parallelization. In addition to compiler support, the OpenMP runtime library is a critical part of the Intel compiler. We present runtime techniques developed in the Intel OpenMP runtime library for exploiting thread-level parallelism as well as integrating the OpenMP support with other forms of threading termed as sibling parallelism. The performance results of a set of benchmarks show good speedups over the well-optimized serial code performance on Intel/spl reg/ Pentium- and Itanium-processor based systems.
2006-01-01 - Predicate Elimination Technique in Binary Translation for IA-64 Architecture	Lessons learnt during the deployment of transition scan content on an IntelÂ® ItaniumÂ® server microprocessor design and its use for electrical debug and defect screening in high-volume manufacturing are described. While many publications in the area of transition scan show it being practiced as an efficient defect screening tool, only a minority of these designs were high-performance microprocessor designs. This work illustrates the benefits of such techniques on complex microprocessors.
2006-01-01 - Using Adaptive Circuits to Mitigate Process Variations in a Microprocessor Design	Ispike is a post-link optimizer developed for the Intel/spl reg/ Itanium Processor Family (IPF) processors. The IPF architecture poses both opportunities and challenges to post-link optimizations. IPF offers a rich set of performance counters to collect detailed profile information at a low cost, which is essential to post-link optimization being practical. At the same time, the predication and bundling features on IPF make post-link code transformation more challenging than on other architectures. In Ispike, we have implemented optimizations like code layout, instruction prefetching, data layout, and data prefetching that exploit the IPF advantages, and strategies that cope with the IPF-specific challenges. Using SPEC CINT2000 as benchmarks, we show that Ispike improves performance by as much as 40% on the ltanium/spl reg/2 processor, with average improvement of 8.5% and 9.9% over executables generated by the Intel/spl reg/ Electron compiler and by the Gcc compiler, respectively. We also demonstrate that statistical profiles collected via IPF performance counters and complete profiles collected via instrumentation produce equal performance benefit, but the profiling overhead is significantly lower for performance counters.
2006-01-01 - Ultra-Fast CPU Performance Prediction: Extending the Monte Carlo Approach	Explicitly-Parallel Instruction Computing (EPIC) provides architectural features, including predication and explicit control speculation, intended to enhance the compiler's ability to expose instruction-level parallelism (ILP) in control-intensive programs. Aggressive structural transformations using these features, though described in the literature, have not yet been fully characterized in complete systems. Using the Intel Itanium 2 microprocessor, the SPECint2000 benchmarks and the IMPACT Compiler for IA-64, a research compiler competitive with the best commercial compilers on the platform, we provide an in situ evaluation of code generated using aggressive, EPIC-enabled techniques in a reality-constrained microarchitecture. Our work shows a 1.13 average speedup (up to 1.50) due to these compilation techniques, relative to traditionally-optimized code at the same inlining and pointer analysis levels, and a 1.55 speedup (up to 2.30) relative to GNU GCC, a solid traditional compiler. Detailed results show that the structural compilation approach provides benefits far beyond a decrease in branch misprediction penalties and that it both positively and negatively impacts instruction cache performance. We also demonstrate the increasing significance of runtime effects, such as data cache and TLB, in determining end performance and the interaction of these effects with control speculation.
2006-01-01 - Piecewise Cubic Interpolation on Distributed Memory Parallel Computers and Clusters of Workstations	HP and Intel's Itanium processor family (IPF) is considered as one of the most challenging processor architectures to generate code for. During global instruction scheduling, the compiler must balance the use of strongly interdependent techniques like code motion, speculation and predication. A too conservative application of these features can lead to empty execution slots, contrary to the EPIC philosophy. But overuse can cause resource shortage which spoils the benefit. We tackle this problem using integer linear programming (ILP), a proven standard optimization method. Our ILP model comprises global, partial-ready code motion with automated generation of compensation code as well as vital IPF features like control/data speculation and predication. The ILP approach can-with some restrictions-resolve the interdependences between these decisions and deliver the global optimum. This promises a speedup for compute-intensive applications as well as some theoretically funded insights into the potential of the architecture. Experiments with several hot functions from the SPEC benchmarks show substantial improvements: our postpass optimizer reduces the schedule lengths produced by Intel's compiler by about 20-40%. The resulting speedup of these routines is 16% on average.
2006-01-01 - Adapting EPIC Architecture's Register Stack for Virtual Stack Machines	Exploiting thread-level parallelism (TLP) is a promising way to improve the performance of applications with the advent of general-purpose cost effective uni-processor and shared-memory multiprocessor systems. In this paper, we describe the OpenMP implementation in the Intel/spl reg/ C++ and Fortran compilers for Intel platforms. We present our major design consideration and decisions in the Intel compiler for generating efficient multithreaded codes guided by OpenMP directives and pragmas. We describe several transformation phases in the compiler for the OpenMP parallelization. In addition to compiler support, the OpenMP runtime library is a critical part of the Intel compiler. We present runtime techniques developed in the Intel OpenMP runtime library for exploiting thread-level parallelism as well as integrating the OpenMP support with other forms of threading termed as sibling parallelism. The performance results of a set of benchmarks show good speedups over the well-optimized serial code performance on Intel/spl reg/ Pentium- and Itanium-processor based systems.
2006-01-01 - Solution of large complex problems in computational electromagnetics using higher-order basis in MoM with out-of-core solvers	Each new microprocessor endeavor strives to achieve the performance gains projected by Moore's law. Such performance arises, in part, from innovative and often from complex microarchitectural features. This trend of increasing functional complexity has already exacerbated the challenge of design validation, making validation the critical path to tapeout. Traditional approaches to functional validation include both focused case writing and the development of random-code generators. In either case, this method is limited to engineering "thought" experiments - the human mind can only process a finite set of states in a seemingly infinite machine state space. In April 2000, the functional model for the Itanium 2 design was nearing tape-out quality. Engineers had written most focused cases to satisfy test plan goals; the random-code generators were mature and pounding away at the RTL model with no restrictions; and the bug rate was steadily decreasing for most units. Despite this encouraging trend, engineers were still concerned with the functional quality of the exception control unit (XPN), one of the most control-logic-intensive units on the chip.
2006-01-01 - High Throughput Total Order Broadcast for Cluster Environments	This paper presents the â€œt-Ringâ€ based DFX access architecture and the testability features of Intel's latest multi-core ItaniumÂ® processor. The architecture solves many common challenges of testing a multi-core CPU using distinctive and innovative solutions. At the core of the architecture is a hierarchical and scalable test access mechanism design providing flexible access for a variety of use models in high volume manufacturing test and debug platforms.
2006-01-01 - Performance modeling using Monte Carlo simulation	In recent years the interior point method (IPM) has became a dominant choice for solving large convex optimization problems for many scientific, engineering and commercial applications. Two reasons for the success of the IPM are its good scalability on existing multiprocessor systems with a small number of processors and its potential to deliver a scalable performance on systems with a large number of processors. The scalability of a parallel IPM is determined by several key issues such as exploiting parallelism due to sparsity of the problem, reducing communication overhead and proper load balancing. In this paper we present an implementation of a parallel linear programming IPM workload and characterize its scalability on a 4-way Itanium/spl reg/ 2 system. We show a speedup of up to 3-times for some of the datasets. We also present a detailed micro-architectural analysis of the workload using VTune/spl trade/ performance analyzer. Our results suggest that a good IPM implementation is latency-bound. Based on these findings, we make suggestions on how to improve the performance of the IPM workload in the future.
2006-01-01 - Inline analysis: beyond selection heuristics	HP-UX compilers inline mathematical functions for Itanium processor family (IPF) systems to improve throughput 4X-8X versus external library calls, achieving speeds comparable to highly tuned vector functions, without requiring the user to code for a vector interface and without sacrificing accuracy or edge-case behaviors. This paper highlights IPF architectural features that support implementation of high-performance, high-quality mathematics functions for inlining. It discusses strategies for utilizing the features and developing inlineable sequences on a large scale, and it presents requisite compiler features and language extensions. Also, this paper describes compiler mechanisms that produce inlineable code and inline it.
2005-01-01 - A design of high speed AGTL+ output buffer	This case study discusses how to use adaptive circuits in a big dual-core microprocessor to combat process variation. The large die size also makes it suffer more on-die process variation. To prevent continuous design updates or multiple design optimizations, designs incorporate adaptive techniques that achieve the highest performance possible. Although adaptive techniques are not new, having been implemented to some degree for generations (for example, self-calibrating I/O), they have taken significant new roles in many design aspects. As adaptive designs proliferate, increasing amounts of effort go into testing them. This article presented two types of adaptive systems: the silicon-optimizing active deskew system and the silicon-monitoring power measurement and cache latent-error detection system. However, these adaptive circuits are the tip of a growing iceberg. As variability increasingly affects designs, designers will likely use more adaptive circuits to achieve the highest performance and reliability possible. New scaling issues, such as erratic bits, will make these adaptations even more necessary to the design's fundamental operation. With increasing use of adaptive circuits, designers will need to develop new test techniques to ensure high part quality and reliability
2001-01-01 - Scientific Computing on the Itanium â„¢ Processor	The design of the high end server processor code named Montecito incorporated several ambitious goals requiring innovation. The most obvious being the incorporation of two legacy cores on-die and at the same time reducing power by 23%. This is an effective 325% increase in MIPS per watt which necessitated a holistic focus on power reduction and management. The next challenge in the implementation was to ensure robust and high frequency circuit operation in the 90-nm process generation which brings with it higher leakage and greater variability. Achieving this goal required new methodologies for design, a greatly improved and tunable clock system and a better understanding of our power grid behavior all of which required new circuits and capabilities. The final aspect of circuit design improvement involved the I/O design for our legacy multi-drop system bus. To properly feed the two high frequency cores with memory bandwidth we needed to ensure frequency headroom in the operation of the bus. This was achieved through several innovations in controllability and tuning of the I/O buffers which are discussed as well.
2005-01-01 - Design of a software distributed shared memory system using an MPI communication layer
2005-01-01 - New Generation Scalable and Dependable Servers
2006-01-01 - Power and temperature control on a 90-nm Itanium family processor	Relaxed memory consistency models are common and essential when multiple processes share a single global address space, such as when using multicore CPUs, partitioned global address space languages, and so forth. Programming within these models is difficult and error prone, because of non-intuitive behaviors that could not occur in a sequential memory consistency model. In addition, because the memory consistency models vary from language to language, and CPU to CPU, a program which may work correctly on one system may not work on another. To address the problem, this paper describes a model checking framework in which users are able to check their programs under various memory consistency models. More specifically, our framework provides a base model that exhibits very relaxed behaviors, and users are able to define various consistency models by adding constraints to the base model. This paper also describes a prototype implementation of a model checker based on the proposed framework. We have specified the necessary constraints for three practical existing memory consistency models (UPC, Coarray Fortran, and Itanium). Our model checker verified some example programs correctly, and confirmed the expected differences among the three models.
2006-01-01 - A 90-nm variable frequency clock system for a power-managed itanium architecture processor	Modern compiler transformations that eliminate redundant computations or reorder instructions, such as partial redundancy elimination and instruction scheduling, are very effective in improving application performance but tend to create longer and potentially more complex live ranges. Typically the task of dealing with the increased register pressure is left to the register allocator. To avoid introduction of spill code which can reduce or completely eliminate the benefit of earlier optimizations, researchers have developed techniques such as live range splitting and rematerialization. This paper describes prematerialization (PM), a novel method for reducing register pressure for VLIW architectures with nop instructions. PM and rematerialization both select "never killed" live ranges and break them up by introducing one or more definitions close to the uses. However, while rematerialization is applied to live ranges selected for spilling during register allocation, PM relies on the availability of nop instructions and occurs prior to register allocation. PM simplifies register allocation by creating live ranges that are easier to color and less likely to spill. We have implemented prematerialization in HP-UX production compilers for the IntelÂ® ItaniumÂ® architecture. Performance evaluation indicates that the proposed technique is effective in reducing register pressure inherent in highly optimized code.
2006-01-01 - The Parity protected, multithreaded register files on the 90-nm itanium microprocessor	A virtualized system includes a new layer of software, the virtual machine monitor. The VMM's principal role is to arbitrate accesses to the underlying physical host platform's resources so that multiple operating systems (which are guests of the VMM) can share them. The VMM presents to each guest OS a set of virtual platform interfaces that constitute a virtual machine (VM). Once confined to specialized, proprietary, high-end server and mainframe systems, virtualization is now becoming more broadly available and is supported in off-the-shelf systems based on Intel architecture (IA) hardware. This development is due in part to the steady performance improvements of IA-based systems, which mitigates traditional virtualization performance overheads. Intel virtualization technology provides hardware support for processor virtualization, enabling simplifications of virtual machine monitor software. Resulting VMMs can support a wider range of legacy and future operating systems while maintaining high performance.
2006-01-01 - The implementation of a 2-core, multi-threaded itanium family processor	In this paper, a general purpose parallel electromagnetic (EM) solver is presented for complicated EM scattering and radiation problems. The parallel algorithm has been designed for multiple platforms and is presented here on four typical operating systems with different hardware, which include IA32 with Windows, IA64 with Windows and EM64T with Linux and Windows operating systems and a DELL PowerEdge 1855 Blade Cluster and Itanium II server in hardware. Techniques have been successfully developed to solve the problem of access to more than 2 GB RAM per process. Since there is no commercial parallel ScaLAPACK solver available for Itanium 2 with Windows Operating System, we also developed ScaLAPACK solver which is presented in this paper. Numerical results shown in this paper indicate that the parallel solver can be run across multiple platforms to solve complicated EM problems very efficiently.
2004-01-01 - Pinpointing Representative Portions of Large Intel Â® Itanium Â® Programs with Dynamic Instrumentation	For nearly 30 years the Hewlett Packard NonStop Enterprise Division (formerly Tandem Computers Inc.) has produced highly available, fault-tolerant, massively parallel NonStop computer systems. These vertically integrated systems use a proprietary operating system and specialized hardware for detecting, isolating, and recovering from faults. The NonStop advanced architecture (NSAA) uses dual or triple modular redundant fault-tolerant servers built from standard HP 4-way SMP Itanium/spl reg/2 server processor modules, memory boards, and power infrastructure. A unique synchronization mechanism allows fully compared operations from loosely synchronized processor modules. In addition, the NSAA improves system availability by additional hardware fault masking, and significantly lowers cost by leveraging existing high-volume Itanium server components.
2004-01-01 - Compiler Optimizations for Transaction Processing Workloads on Itanium Â® Linux Systems	Low-voltage computing is emerging as a promising energy-efficient solution to power-constrained environments. Unfortunately, low-voltage operation presents significant reliability challenges, including increased sensitivity to static and dynamic variability. To prevent errors, safety guard bands can be added to the supply voltage. While these guard bands are feasible at higher supply voltages, they are prohibitively expensive at low voltages, to the point of negating most of the energy savings. Voltage speculation techniques have been proposed to dynamically reduce voltage margins. Most require additional hardware to be added to the chip to correct or prevent timing errors caused by excessively aggressive speculation. This paper presents a mechanism for safely guiding voltage speculation using direct feedback from ECC-protected cache lines. We conduct extensive testing of an Intel Itanium processor running at low voltages. We find that as voltage margins are reduced, certain ECC-protected cache lines consistently exhibit correctable errors. We propose a hardware mechanism for continuously probing these cache lines to fine tune supply voltage at core granularity within a chip. Moreover, we demonstrate that this mechanism is sufficiently sensitive to detect and adapt to voltage noise caused by fluctuations in chip activity. We evaluate a proof-of-concept implementation of this mechanism in an Itanium-based server. We show that this solution lowers supply voltage by 18% on average, reducing power consumption by an average of 33% while running a mix of benchmark applications.
2006-01-01 - Beating in-order stalls with "flea-flicker" two-pass pipelining	Co-array Fortran (CAF) - a small set of extensions to Fortran 90 - is an emerging model for scalable, global address space parallel programming. CAF's global address space programming model simplifies the development of single-program-multiple-data parallel programs by shifting the burden for managing the details of communication from developers to compilers. This paper describes CAFC - a prototype implementation of an open-source, multiplatform CAF compiler that generates code well-suited for today's commodity clusters. The CAFC compiler translates CAF into Fortran 90 plus calls to one-sided communication primitives. The paper describes key details of CAFC's approach to generating efficient code for multiple platforms. Experiments compare the performance of CAF and MPI versions of several NAS parallel benchmarks on an Alpha cluster with a Quadrics interconnect, an Itanium 2 cluster with a Myrinet 2000 interconnect and an Itanium 2 cluster with a Quadrics interconnect. These experiments show that CAFC compiles CAF programs into code that delivers performance roughly equal to that of hand-optimized MPI programs.
2005-01-01 - Tools and Products	Dynamic information flow tracking (also known as taint tracking) is an appealing approach to combat various security attacks. However, the performance of applications can severely degrade without hardware support for tracking taints. This paper observes that information flow tracking can be efficiently emulated using deferred exception tracking in microprocessors supporting speculative execution. Based on this observation, we propose SHIFT, a low-overhead, software-based dynamic information flow tracking system to detect a wide range of attacks. The key idea is to treat tainted state (describing untrusted data) as speculative state (describing deferred exceptions). SHIFT leverages existing architectural support for speculative execution to track tainted state in registers and needs to instrument only load and store instructions to track tainted state in memory using a bitmap, which results in significant performance advantages. Moreover, by decoupling mechanisms for taint tracking from security policies, SHIFT can detect a wide range of exploits, including high-level semantic attacks. We have implemented SHIFT using the Itanium processor, which has support for deferred exceptions, and by modifying GCC to instrument loads and stores. A security assessment shows that SHIFT can detect both low-level memory corruption exploits as well as high-level semantic attacks with no false positives. Performance measurements show that SHIFT incurs about 1% overhead for server applications. The performance slowdown for SPEC-INT2000 is 2.81X and 2.27X for tracking at byte-level and wordlevel respectively. Minor architectural improvements to the Itanium processor (adding three simple instructions) can reduce the performance slowdown down to 2.32X and 1.8X for byte-level and word-level tracking, respectively.
2005-01-01 - The implementation of a 2-core, multi-threaded Itanium/spl reg/ family processor	State-of-the-art multiprocessor systems pose several difficulties: (i) the user has to parallelize the existing serial code; (ii) explicitly threaded programs using a thread library are not portable; (iii) writing efficient multi-threaded programs requires intimate knowledge of machine's architecture and micro-architecture. Thus, well-tuned parallelizing compilers are in high demand to leverage state-of-the-art computer advances of NUMA-based multiprocessors, simultaneous multi-threading processors and chip-multiprocessor systems in response to the performance quest from the high-performance computing community. On the other hand, OpenMP* has emerged as the industry standard parallel programming model. Applications can be parallelized using OpenMP with less effort in a way that is portable across a wide range of multiprocessor systems. In this paper, we present several practical compiler optimization techniques and discuss their effect on the performance of OpenMP programs. We elaborate on the major design considerations in a high performance OpenMP compiler and present experimental data based on the implementation of the optimizations in the IntelÂ® C++ and Fortran compilers. Interactions of the OpenMP transformation with other sequential optimizations in the compiler are discussed. The techniques in this paper have achieved significant performance improvements on the industry standard SPEC* OMPM2001 and SPEC* OMPL2001 benchmarks, and these performance results are presented for IntelÂ® PentiumÂ® and ItaniumÂ® processor based systems.
2005-01-01 - Clock distribution on a dual-core, multi-threaded Itanium/spl reg/ family microprocessor	In this paper, we evaluate the benefits achievable from software data-prefetching techniques for OpenMP* C/C++ and Fortran benchmark programs, using the framework of the Intel production compiler for the Intel/spl reg/ Itanium/spl reg/ 2 processor. Prior work on software data-prefetching study has primarily focused on benchmark performance in the context of a few software data-prefetching schemes developed in research compilers. In contrast, our study is to examine the impact of an extensive set of software data-prefetching schemes on the performance of multi-threaded execution using a full set of SPEC OMPM2001 applications with a product compiler on a commercial multiprocessor system. This paper presents performance results showing that compiler-based software data-prefetching supported in the Intel compiler results in significant performance gain, viz., 11.88% to 99.85% gain for 6 out of 11 applications, 3.83% to 6.96% gain for 4 out of 11 applications, with only one application obtaining less than 1% gain on an Intel/spl reg/ Itanium/spl reg/ 2 processor based SGI Altix* 32-way shared-memory multiprocessor system.
2005-01-01 - Clock distribution on a dual-core, multi-threaded Itanium/sup /spl reg//-family processor	This works presents the porting on the grid of a parallel application of phylogenetic inference, MrBayes, in the LIBI (International Laboratory of Bioinformatics) platform. Moreover a bioinformatic case study about the analysis of 11 phylogenies, including a series of large sequences data sets that represent the nascent barcode reference database for Lepidoptera is also presented. The case study has been tested on the platform and the speedup and efficiency on Itanium HP XC6000 (Intel Itanium 2 processors and Quadrics interconnects) of the SPACI consortium, University of Salento, are described.
2005-01-01 - The implementation of a 2-core multi-threaded Itanium/spl reg/-family processor	The scalability port (SP) is a point-to-point cache consistent interface to build scalable shared memory multiprocessors. The SP interface consists of three layers of abstraction: the physical layer, the link layer and the protocol layer. The physical layer uses pin-efficient simultaneous bi-directional signaling and operates at 800 MHz in each direction. The link layer supports virtual channels and provides flow control and reliable transmission. The protocol layer implements cache consistency, TLB consistency, synchronization, and interrupt delivery functions among others. The first implementation of the SP interface is in the Intel/sup /spl reg// E8870 and E9870 chipset for the Intel Itanium/sup /spl reg//2 processor and future generations of the Itanium processor family.
2005-01-01 - Power and temperature control on a 90nm Itanium/sup /spl reg//-family processor	The drastic increase in power consumption by modern processors emphasizes the need for power-performance trade-offs in architecture design space exploration and compiler optimizations. This paper reports a quantitative study on the power-performance trade-offs in software pipelined schedules for an Itanium-like EPIC architecture with dual-speed pipelines, in which functional units are partitioned into fast ones and slow ones. We have developed an integer linear programming formulation to capture the power-performance tradeoffs for software pipelined loops. The proposed integer linear programming formulation and its solution method have been implemented and tested on a set of SPEC2000 benchmarks. The results are compared with an Itanium-like architecture (baseline) in which there are four functional units (FUs) and all of them are fast units. Our quantitative study reveals that by introducing a few slow FUs in place of fast FUs in the baseline architecture, the total energy consumed by FUs can be considerably reduced. When 2 out of 4 FUs are set as slow, the total energy consumed by FUs is reduced by up to 31.1% (with an average reduction of 25.2%) compared with the baseline configuration, while the performance degradation caused by using slow FUs is small. If performance demand is less critical, then energy reduction of up to 40.3% compared with the baseline configuration can be achieved.
2005-01-01 - The asynchronous 24MB on-chip level-3 cache for a dual-core Itanium/sup /spl reg//-family processor	In this paper, we describe Peppermint and Sled: tools developed for evaluations of computer systems based on IA-64 processors. Sled generates trace from applications running on IA-64 processors, while Peppermint models the complete system using cycle-accurate, trace-driven simulation. Peppermint is based on Augmint, which leaves open the possibility of doing execution-driven simulations in future. Peppermint and Sled allow us to perform a trace-based evaluation of 4 applications running on SMP systems based on Itanium and McKinley processors. We find that the improvement in IPC of McKinley relative to Itanium ranges from 7% to over 100% for our different applications. The improvement can be attributed to a variety of factors. These range from the availability of additional functional units and issue ports in the McKinley processor to our assumption of a better memory system. While the improvement in performance remains valid in SMP systems in some cases, higher contention for system bus and memory reduces the performance gain in other cases. Increasing the system bits bandwidth and size of queues for pending requests in the memory controller are identified as first steps for optimizing SMP performance.
2005-01-01 - A 90nm variable-frequency clock system for a power-managed Itanium/sup /spl reg//-family processor	Modern processors based on VLIW architecture rely heavily on software cache prefetching incorporated by the compiler. For accurate prefetching different factors such as latencies of the loop iterations need to be taken into account, which cannot be determined at (static) compile time. Consequently, the compilers either produce inaccurate prefetches or resort to producing code without prefetching. Many applications with complex code are therefore unable to perform very well on the modern processors. In this paper, we present an approach that is able to generate accurate prefetch instructions by exploiting information available at runtime. The code is instrumented with prefetches having offsets which may be adapted at runtime through a dynamic code specializer. Such cache prefetching with dynamic adaptation results in better performance of the applications. The runtime code generation activity is highly efficient and incurs a very small overhead. The experiments performed on Itanium-II architecture using icc and gcc compilers produce an average speedup of 2.51% and 2.56%, respectively.
2005-01-01 - The multi-threaded, parity-protected 128-word register files on a dual-core Itanium/sup /spl reg//-family processor	Single processor performance has exhibited substantial growth over the last three decades [1] as shown in Figure 1. What is also desired are techniques which enable connecting together multiple processors in order to create scalable, modular and resilient multiprocessor systems. Beginning with the production of the IntelÂ® XeonÂ® processor 5500 series, (previously codenamed â€œNehalem-EPâ€), the IntelÂ® XeonÂ® processor 7500 series (previously codenamed â€œNehalem-EXâ€), and the IntelÂ® Itaniumâ„¢ processor 9300 series (previously codenamed â€œTukwila-MCâ€), Intel Corporation has introduced a series of multi-core processors that can be easily interconnected to create server systems scaling from 2 to 8 sockets. In addition, OEM platforms are currently available that extend this up to 256-socket server designs1. This scalable system architecture is built upon the foundation of the IntelÂ® QuickPath Interconnect (Intel QPI). These Intel micro-architectures provide multiple high-speed (currently up to 25.6 GB/s), point-to-point connections between processors, I/O hubs and third party node controllers. The interconnect features, as well as the capabilities built into the processor's system interconnect logic (also known as â€œuncoreâ€), work together to deliver the performance, scalability, and reliability demanded in larger scale systems.
2000-01-01 - ItaniumTMprocessor system bus design	This paper presents the software suite dubbed automated manufacturing technology (AMT) that monitors and controls the hundreds of steps wafers must pass through on their way to becoming Pentium, Itanium, and Core 2 Duo processors, as well as other high-end Intel microprocessors. The AMT suite has four major components: the manufacturing execution system, the process control automation framework, the engineering analysis framework, and the material handling and tool control. Each is composed of several programs, and each of those programs controls a different part of the chip-making process. The paper also presents how the grid improves the manufacturing flow and the R&D process by looking at a 25-piece lot of experimental wafers called Lot X500
2005-01-01 - NonStop/spl reg/ advanced architecture	Hadrons generated by the primary cosmic rays penetrating the atmosphere have a negative impact on the reliability of semiconductor devices. The electrical charge induced by high energy particles manifests as a current spike and can affect both storage elements and combinational logic. Frequency of occurrence of the errors induced by this failure mechanism is referred to as soft error rate (SER). Continuous shrinking of the electronic devices and the lower supply voltages, in conjunction with the increased complexity of VLSI circuits, has led to higher SER. The impact of semiconductor technology scaling on neutron induced SER is discussed in this report. The experimental methodology and results of accelerated measurements carried out on Intel Itanium/spl reg/ microprocessors, at Los Alamos Neutron Science Center (LANSCE), are presented. Statistically significant values of the MTTF induced by high-energy neutrons are also derived, as a function of the number of upsets observed over the duration of the experiment. The presented approach doesn't require any proprietary data about the microprocessor under evaluation and, as a consequence, can be used as a dependability benchmarking tool both by manufacturers and independent evaluators.
2005-01-01 - Neutron SER characterization of microprocessors	Cycle accurate simulation has long been the primary tool for micro-architecture design and evaluation. Though accurate, the slow speed often imposes constraints on the extent of design exploration. In this work, we propose a fast, accurate Monte-Carlo based model for predicting processor performance. We apply this technique to predict the CPI of in-order architectures and validate it against the Itanium-2. The Monte Carlo model uses micro-architecture independent application characteristics, and cache, branch predictor statistics to predict CPI with an average error of less than 7%. Since prediction is achieved in a few seconds, the model can be used for fast design space exploration that can efficiently cull the space for cycle-accurate simulations. Besides accurately predicting CPI, the model also breaks down CPI into various components, where each component quantifies the effect of a particular stall condition (branch misprediction, cache miss, etc.) on overall CPI. Such a CPI decomposition can help processor designers quickly identify and resolve critical performance bottlenecks
2005-01-01 - Some functions computable with a fused-mac	The fused multiply accumulate-add (FMA) instruction, specified by the IEEE 754-2008 Standard for Floating-Point Arithmetic, eases some calculations, and is already available on some current processors such as the Power PC or the Itanium. We first extend an earlier work on the computation of the exact error of an FMA (by giving more general conditions and providing a formal proof). Then, we present a new algorithm that computes an approximation to the error of an FMA, and provide error bounds and a formal proof for that algorithm.
2005-01-01 - N-bit unsigned division via n-bit multiply-add	We propose an ANSI/IEEE-754 double precision floating-point matrix-vector multiplier. Its main feature is the capability to process efficiently both dense matrix-vector multiplications (DMVM) and sparse matrix-vector multiplications (SMVM). The design is composed of multiple processing elements (PE) and is optimized for FPGAs. We investigate theoretically the boundary conditions when the DMVM equals the SMVM performance with respect to the matrix sparsity. Thus, we can determine the most efficient processing mode configuration with respect to the input data sparsity. Furthermore, we evaluate our design both with simulations and on real hardware. We experimented on an Altix 450 machine using the SGI reconfigurable application specific computing (RASC) services, which couple dual-core Itanium-2 processors with Virtex-4 LX200 FPGAs. Our design has been routed and executed on the Altix 450 machine at 100 MHz. Experimental results suggest that only two PEs suffice to outperform the pure software SMVM execution. The performance improvement at the kernel level scales near linearly to the number of configured PEs both for the SMVM and DMVM. Compared to related work, the design does not indicate any performance degradation and performs equally or better than designs optimized either for SMVM or DMVM alone.
2005-01-01 - Montecito: a dual-core, dual-thread Itanium processor	The fused multiply accumulate instruction (fused-mac) that is available on some current processors such as the Power PC or the Itanium eases some calculations. We give examples of some floating-point functions (such as ulp(x) or Nextafter(x, y)), or some useful tests, that are easily computable using a fused-mac. Then, we show that, with rounding to the nearest, the error of a fused-mac instruction is exactly representable as the sum of two floating-point numbers. We give an algorithm that computes that error.
2005-01-01 - Seven-O'Clock: a new distributed GVT algorithm using network atomic operations	Leakage power is projected to be one of the major challenges in future technology generations. The temperature profile, process variation, and transistor count all have strong impact on the leakage power distribution of a processor. We have built a simulator to estimate the dynamic/leakage power for a VLIW architecture considering dynamic temperature feedback and process variation. The framework is based on architecture similar to the Intel Itanium IA64 and is extended to simulate its power when implemented in 65nm technology. Our experimental results show that leakage power will become more than 50% of the power budget in 65nm technology. Moreover, without including the process variation, the total leakage power will be underestimated by as much as 30%.
2004-01-01 - Construction and performance characterization of parallel interior point solver on 4-way Intel Itanium 2 multiprocessor system	To make the MoM code more applicable to real world problems, an efficient load-balancing MPI based parallel MoM solver is presented here. An efficient matrix filling scheme is presented to make the parallelization more convenient and efficient. The code has been successfully compiled with Windows and Linux operating systems and run on different Platforms such as DELL 1855 Cluster and HP Itanium 2 Server. Several numerical results have been presented to demonstrate the high parallel efficiency and the portability of the code.
2005-01-01 - Intel virtualization technology	Software-implemented fault injection is an established method to emulate hardware faults in computer systems. Existing approaches typically extend the operating system by special drivers or change the application under test. We propose a novel approach where fault injection capabilities are added to the computer firmware. This approach can work without any modification to operating system and / or applications, and can support a larger variety of fault locations. We discuss four different strategies in X86/X64 and Itanium systems. Our analysis shows that such an approach can increase portability, the non-intrusiveness of the injector implementation, and the number of supported fault locations. Firmware-level fault injection paves the way for new research directions, such as virtual machine monitor fault injection or the investigation of certified operating systems.
2005-01-01 - An empirical study of data speculation use on the Intel Itanium 2 processor	In this work we propose a set of compiler optimizations to identify and remove redundant checks from the replicated code. Two checks are considered redundant if they check the same variable. In this work we evaluate two levels of hardware or system support: memory without support for checkpointing and rollback, where memory is guaranteed to not be corrupted with wrong values and memory with low-cost support for checkpointing and rollback. We also consider the situation where register file is protected with parity or ECC, such as Intel Itanium, Sun UltraSPARC and IBM Power4-6 because software implementations can take advantage of this hardware feature and reduce some of the replicated instructions. We have evaluated our approach using LLVM as our compiler infrastructure and PIN for fault injection. Our experimental results with Spec benchmarks on a Pentium 4 show that in the case where memory is guaranteed not to be corrupted, performance improves by an average 6.2%. With more support for checkpoint performance improves by an average 14.7%. A software fault tolerant system that takes advantage of the register safe platforms improves by an average 16.0%. Fault injection experiments show that our techniques do not decrease fault coverage, although they slightly increase the number of segmentation faults.
2004-01-01 - Early performance results on the NRL SGI Altix 3000 computer	Software engineering studies have shown that programmer productivity is improved through the use of computational science integrated development environments (or CSIDE, pronounced "sea side") such as MATLAB. ParaM is a CSIDE distribution which provides parallel execution of MATLAB scripts for HPC systems. ParaM runs on a range of processor architectures (e.g., x86, x64, Itanium, PowerPC) and its MPI binding, known as bcMPI, supports a number of interconnect architectures (e.g., Myrinet and Infinband). In this paper, we describe our goals for the ParaM project, the current status of the project and report on initial software engineering successes and challenges.
2005-01-01 - Analysis of path profiling information generated with performance monitoring hardware	The problem of sorting has been studied extensively and many algorithms have been suggested in the literature for the problem. Literature on parallel sorting is abundant. Many of the algorithms proposed, though being theoretically important, may not perform satisfactorily in practice owing to large constants in their time bounds. The algorithms presented in this paper have the potential of being practical. We suggest some novel sorting mechanisms specific to the cell broadband engine. We try to utilize the specifics of its architecture in order to get the optimum performance. As part of our comparative analysis we juxtapose these algorithms with similar ones implemented on Itanium 2 processor as well as the Pentium 4 processor.
2005-01-01 - Optimizing structures in object oriented programs	High-performance reconfigurable computers (HPRCs) consisting of CPUs with application-specific FPGA accelerators traditionally use a low-level hardware-description language such as VHDL or Verilog to program the FP-GAs. The complexity of hardware design methodologies for FPGAs requires specialist engineering knowledge and presents a significant barrier to entry for scientific users with only a software background. Recently, a number of High-Level Languages (HLLs) for programming FPGAs have emerged that aim to lower this barrier and abstract away hardware-dependent details. This paper presents the results of a study on implementing hardware accelerators using the Mitrion-C HLL. The implementation of two floating-point scientific kernels: dense matrix-vector multiplication (DMVM) and the computation of spherical boundary conditions in molecular dynamics (SB) are described. We describe optimizations that are essential for taking advantage of both the features of the HLL and the underlying HPRC hardware and libraries. Scaling of the algorithms to multiple FPGAs is also investigated. With four FPGAs, 80 times speedup over an Itanium 2 CPU was achieved for the DMVM, while a 26 times speedup was achieved for SB.
2005-01-01 - Impact of compiler-based data-prefetching techniques on SPEC OMP application performance	Designing a chip set for a new processor architecture like the IA-64 requires handling multiple aspects. They include implementing the processor interface; providing sufficient I/O bandwidth for servers; supporting accelerated graphics port (AGP) graphics; and providing sufficient memory bandwidth for the processor, I/O, and graphics. This article provides an introduction to the memory, I/O, and graphics subsystems of Intel's Itanium processor chip set and discusses several aspects of the processor bus.
2005-01-01 - SWIFT: software implemented fault tolerance	Summary form only given. Open64 was originally developed by SGI and released as the MlPSpro compiler. It has been well recognized as an industrial-strength production compiler for high-performance computing. It includes advanced inter-procedural optimizations, loop nest optimizations, global scalar optimizations, and code generation with advanced global register allocation and software pipelining. It was open-sourced in 2000 after it was retargeted to the Itanium processor. Now, Open64 is accepted by many compiler researchers as a good infrastructure for research on new compiler optimizing technologies, especially the for the emerging multi-core/many-core architecture.
2004-01-01 - Hardware Support for Prescient Instruction Prefetch	Since December 2002 the Naval Research Laboratory (NRL) has been evaluating an Altix 3000, the newest high performance computing system available from Silicon Graphics, Inc. (SGI). The Altix is a departure from the previous products from SGI in that instead of using MIPS processors and the IRIX operating system, the Altix uses the Intel Itanium IA-64 processor and SGI ProPack (based on Linux Red Hat) operating system. The Altix still has the brick concept of system configuration and the SGI NUMAlink for the inter-module network for the shared memory. The Altix runs under a single image of the operating system and supports parallel programming through OpenMP, MPI, CoArray, FORTRAN, and an automatic parallelizing compiler. Various codes have been evaluated with respect to their ease of portability and their performance on the Altix as compared to other high performance computers.
2004-01-01 - Data Centric Cache Measurement on the Intel ltanium 2 Processor	The National Science Foundation (NSF) recently released a set of application benchmarks that would be a key factor in selecting the next-generation high- performance computing environment. These benchmarks are designed to capture the salient attributes of those science and engineering applications placing the most stringent demands on the system to be provisioned. The application benchmarks consist of six codes that require large amount of memory and work with large data sets. In this work, we study the complexity, performance, and scalability of these codes on four machines: a 512-processor SGI Altix 3700, a 512-processor SGI Altix 3700/BX2, a 512-processor dual-core based SGI Altix 4700, and a 128-processor Cray Opteron cluster interconnected by the Myrinet network. We evaluated these codes for two different problem sizes using different numbers of processors. Our results show that per processor the SGI machines, using the Intel Itanium-2 processor, are faster than the Cray cluster, using the AMD Opteron processor, by a factor of up to three. Also, we found out that some of these codes scale up very well as we increase the number of processors while others scaled up poorly. In addition, one of the codes achieved about 2/3 of the peak rate of an SGI Altix processor. Moreover, the dual-core based system achieved comparable performance results to the single-core based system. Finally, we provide some limitations and concluding remarks.
2005-01-01 - Unpredication, unscheduling, unspeculation: reverse engineering Itanium executables	In the high-profile electronics industry, a new microprocessor architecture is enough of a rarity to excite great anticipation. In the first year of the third millennium, industry watchers will have plenty to look forward to, as the first batch of high-end computers built with Intel Corp.'s new microprocessor, Itanium (formerly Merced), becomes available. This year could also mark the beginning of the end for microprocessors with clock rates below a gigahertz. Leading the attack will be the Power4 processor chip from IBM Corp. and the Alpha 21364 from Compaq Computer Corp., both slated to run at speeds of 1 GHz and higher.
2005-01-01 - A 130-nm triple-V/sub t/ 9-MB third-level on-die cache for the 1.7-GHz Itanium/spl reg/ 2 processor	The newest SGI Altix system is the 4000 series that uses dual-core Itanium-2 p9000 series processors. It differs from the Altix 3000 series in the processor architecture and in the type and number of the component modules. Here we compare and contrast between the Altix 4700 and Altix 3700/BX2 using a set of communication benchmarks, kernel benchmarks, and NSF application benchmarks. The communication benchmarks show that the 4700 has a higher effective bandwidth than the 3700/BX2 while the computation benchmarks show the two systems perform at comparable rates except where the application was able to take advantage of a larger L2 cache and faster memory bus on the 4700.
2004-01-01 - ChipPower: an architecture-level leakage simulator	The inherent complexity in utilizing and programming high performance computing (HPC) systems is the main obstacle to widespread exploitation of HPC resources and technologies in the Department of Defense (DoD). Consequently, there is the persistent need to simplify the programming interface for the generic user. This need is particularly acute in the Signal/Image Processing (SIP), Integrated Modeling and Test Environments (IMT), and related DoD communities where typical users have heterogeneous unconsolidated needs. Mastering the complexity of traditional programming tools (C, MPI, etc.) is often seen as a diversion of energy that could be applied to the study of the given scientific domain. Many SIP users instead prefer high-level languages (HLLs) within integrated development environments, such as MATLAB. We report on our collaborative effort to use a HLL distribution for HPC systems called ParaM to optimize and parallelize a compute-intensive Superconducting Quantum Interference Filter (SQIF) application provided by the Navy SPAWAR Systems Center in San Diego, CA. ParaM is an open-source HLL distribution developed at the Ohio Supercomputer Center (OSC), and includes support for processor architectures not supported by MATLAB (e.g., Itanium and POWER5) as well as support for high-speed interconnects (e.g., InfiniBand and Myrinet). We make use of ParaM installations available at the Army Research Laboratory (ARL) DoD Supercomputing Resource Center (DSRC) and OSC to perform a successful optimization/parallelization of the SQIF application. This optimization/parallelization may be used to assess the feasibility of using SQIF devices as extremely sensitive detectors for electromagnetic radiation which is of great importance to the Navy and DoD in general.
2004-01-01 - Agile methods applied to embedded firmware development	The aim of this paper is to present two new portable and high performance implementations of routines that can be used for piecewise cubic interpolation. The first one (sequential) is based on LAPACK routines, while the next, based on ScaLAPACK is designed for distributed memory parallel computers and clusters. The results of experiments performed on a cluster of twenty Itanium 2 processors and on Cray XI are also presented and shortly discussed
2004-01-01 - In-system FPGA prototyping of an Itanium microarchitecture	The register stack (RS) is a major component of the explicit parallel instruction computer (EPIC) architecture. In this paper, our objective is to close the theoretical performance gap between EPIC and stack processors running virtual stack machines - using forth, a simple and canonical stack machine. For this purpose, we first introduce a new calling mechanism using the RS to implement a software-only virtual stack machine. Based upon our performance measurements, we show that the new calling mechanism is a promising technique to improve the performance of stack-based interpretative virtual machines. But limitation in EPIC makes the need for hardware support to reach optimal performance. As a second step, we define an addition to Itanium 2 processor's instruction set to accommodate the new calling mechanism. As our third and last step, we describe a conservative architectural implementation of the extended instruction set
2004-01-01 - New chips stop buffer overflow attacks	Software engineering studies have shown that programmer productivity is improved through the use of computational science integrated development environments (or CSIDE, pronounced "sea side") such as MATLAB. ParaM is a CSIDE distribution which provides parallel execution of MATLAB scripts for high performance computing (HPC) systems. ParaM runs on a range of processor architectures (e.g., x86, x64, Itanium, PowerPC) and its Message Passing Interface (MPI) binding, known as bcMPI, supports a number of interconnect architectures (e.g., Myrinet and Infinband). In this paper, we describe our goals for the ParaM project, the current status of the project and report on successes and challenges of ParaM support on High Performance Computing Modernization Program (HPCMP) systems at the US Army Research Laboratory (ARL) and the Aeronautical Systems Center (ASC).
2004-01-01 - A multi-platform co-array Fortran compiler	In this paper, we present a detailed case study of the optimizing implementation of a fundamental scientific kernel, matrix-vector multiplication, on FT64, which is the first 64-bit stream processor designed for scientific computing. The major novelties of our study are as follows. First, we develop four stream programs according to different stream organizations, involving dot product, row product, multi-dot product and multi-row product approaches. Second the optimal strip size for partitioning the large matrix is put forward based on a practical parameter model. Finally loop unrolling and software pipelining are used to hide the communications with the computations. The experimental results show that the optimizing implementations on FT64 achieve high speedup over the corresponding Fortran programs running on Itanium 2. It is certain that matrix-vector multiplication can efficiently exploit the tremendous potential of FT64 stream processor through programming optimizations.
2004-01-01 - A compiler framework for recovery code generation in general speculative optimizations	Fast and accurate evaluation of elementary functions (e.g. 1/ x , log, 3âˆšx, and 1/âˆšx) is vital in many computation intensive applications. This paper presents a synthesis system of a unified hardware unit for evaluating a custom subset of elementary functions. Based on some latest algorithms of software library and new design principles that exploit the parallelism of reconfigurable hardware, fast and compact datapath is automatically generated. The proposed system also enables rapid design space exploration by allowing designers to modify the constraints on each function (e.g. precision, delay, area, etc.). For an arbitrary set of logarithm functions and power series, accuracy around 0.6 ulp (unit of last place) is achieved at double precision, which is 0.3 ulp more accurate than PentiumÂ®, and the speed is 30% faster than ItaniumÂ®. The result is simulated by 80nm process.
2004-01-01 - A 0.13/spl mu/m triple-Vt 9MB third level on-die cache for the Itanium/spl reg/ 2 processor	Technology scaling leads to reduction of supply voltage and increase in random device variability and thus creates new challenges for analog design. A complete overhaul of the design approach at system architecture and circuit topology levels is necessary to keep the link robust and tolerant to low supply voltage and random variability challenges. This paper presents key analog circuit architecture techniques employed to implement 6.4GT/s per lane, 14mW/Gbps analog front end high-speed IO interfaces on Poulson - a 32nm next generation Intel Itanium microprocessor [1].
2004-01-01 - Improving load/store queues usage in scientific computing	The FT64 stream processor is a 64-bit stream processor for scientific computing. It is necessary to research efficient implementation of scientific applications on FT64 to exploit the powerful ability. Matrix-matrix multiplication is an important kernel used in many scientific applications. In this paper, we develop two stream implementations of matrix-matrix multiplication on FT64, and optimize these versions by using stripmining technique. Our efforts aim at reducing memory access overhead and improving computational intensiveness. The experimental results show that the optimizing implementations on FT64 achieve high speedup over the corresponding fortran programs running on Itanium 2. It is certain that matrix-matrix multiplication can efficiently exploit the tremendous potential of FT64 processor through programming optimizations.
2004-01-01 - Applying MPI derived datatypes to the NAS benchmarks: A case study	Software pipelining is a loop optimization technique used to exploit instruction level parallelism in the loop. EPIC architectures, such as Intel IA-64 (Itanium) provide extensive hardware support for software pipelining to generate compact and highly parallel code. However it transforms explicit conditional branches into implicit control flow based on the information of the guard registers. It is difficult to reconstruct precise control flow from the optimized code. This paper describes an approach to reconstruct implicit control flow in modulo scheduled loops and thereby improve the quality of reverse engineering optimized executables. We also demonstrate the effectiveness of this approach through experiment results.
2004-01-01 - Methodology for automated layout migration for 90nm Itanium/spl reg/2 processor design	A novel chemical micro-gas sensor array composed of polyaniline (PANI) and its nanocomposite thin film was fabricated for NH3, CO and H2 gas classification. Itanium dioxide (TiO2), indium oxide (In2O3) and multi-walled carbon nanotube (PANI/MWNT) combined with PANI were chosen as the sensing materials by the step-clustering analysis. The normalization method was developed to eliminate the dispersion of the array data. Probabilistic neuron network (PNN) was designed and trained with the processed data, and the different discrimination results were discussed under the different spread constant (SP). The accurate classification result was achieved when SP was set as 0.05 or 0.1.
2004-01-01 - Ispike: a post-link optimizer for the Intel/spl reg/ Itanium/spl reg/ architecture	Todayâ€™s applications are being built in new ways. The advent of service-oriented architectures, modern networking protocols and industry-standard components at all levels open seemingly endless possibilities for new applications and services. But these new possibilities carry new challenges as well, especially in the area of highperformance, mission-critical, transactional applications, often involving financial and other sensitive data which carries security and auditability requirements. This talk will focus on the particular challenges for servers and how these challenges are being addressed. The NonStop Enterprise Division of HP (formerly Tandem Computers) has built massively parallel, hardware and software fault-tolerant servers since 1975. These servers power many of the most challenging transaction processing environments that exist, including major stock exchanges, funds transfer applications, credit and debit card applications, E911 applications, major telephony and instant messaging applications, and integrated hospital applications. The system is based on a message-oriented architecture and thus bears many similarities internally to the architectural principals being espoused for todayâ€™s service-oriented architectures. HP is bringing to market a new generation of Integrity NonStop Servers, based on an innovative design using Intel Itanium 2 processors and leveraging many other industry standards. This talk will describe how the new generation of servers can accomplish even higher levels of availability than current systems while at the same time leveraging industry standards and meeting other extreme requirements. The talk will also touch on the lessons learned over the years when dealing with mission-critical applications and how those lessons apply to todayâ€™s distributed, service-oriented architectures. The underlying message is that careful use of encapsulation, limiting the use of distributed algorithms to carefully controlled situations, and overall design rigor are required even more than ever.
2004-01-01 - Exploring the performance potential of Itanium/spl reg/ processors with ILP-based scheduling	Modern compression standards such as H.264, DivX, or VC-1 provide astonishing quality at the costs of steadily increasing processing requirements. Therefore, efficient solutions for mobile multimedia devices have to effectively leverage instruction level parallelism (LLP), which is often achieved by the deployment of EPIC (explicitly parallel instruction computing) architectures. A characteristical architectural feature to increase the available ILP in the presence of control flow is predicated execution. Compilers targeting those hardware platforms are responsible to carefully convert control flow into conditional/predicated instructions - a process called if-conversion. We describe an effective if-conversion algorithm for the CHILI - a novel hardware architecture specifically designed for digital video processing and mobile multimedia consumer electronic. Several architectural characteristics such as the lack of branch prediction units, large delay slots, and the provided predication model are significantly different from previous work, typically aiming mainstream architectures such as Intel Itanium. The algorithm has been implemented for an optimizing compiler based on LLVM. Experimental results using a cycle accurate simulator for the well known benchmark suite MiBench and several multimedia codecs show a speed improvement of about 18% on average. On the same programs, our compiler achieves a speedup of 21% in comparison to the existing code generator based on gcc.
2004-01-01 - SYZYGY - a framework for scalable cross-module IPO	AGTL+ (assisted Gunning transceiver logic+) signal transmission and interface technology are analyzed in this paper. To resolve the problem on such short high-level duration time in traditional design, we have proposed an auxiliary charged circuit structure. According to what I have analyzed, we design and realize an AGTL+ interface circuit, which is completely compatible with Itanium 2 interface and has high-speed and high noise margin. The operating frequency of circuit reaches to 500MHz by SPICE simulation in the condition of 0.18mum standard CMOS process
2004-01-01 - Improving 64-bit Java IPF performance by compressing heap references	We describe the implementation of a hardware-accelerated particle graphics engine on a reconfigurable computer. The engine incorporates a configurable flow model that enables the simulation of complex spatially-dependent particle graphics effects. The FPGA particle engine was designed using the Mitrion-C high-level language, and did not require detailed hardware design. The engine was implemented on a SGI Altix 350 with four Xilinx Virtex-4 LX200 FPGAs. The engine achieves speedups of 35 to 58 times over a 1.5 GHz Itanium 2 CPU when using one and four FPGAs respectively.
2004-01-01 - Itanium 2 processor 6M: higher frequency and larger L3 cache	Self-consistent 3-D FDTD analysis of a bounded-wave EMP simulator with a human model in the presence of a complex electrical environment is performed. The designed EMP simulator could be directly applied to the optimization of EMP for a desired level of the field intensity and risetime in UWB pulsed applications. Using a fine mesh and an Itanium II 160 processor cluster allowed the risetime of 1.4 ns - very close to the experimental design of 1 ns. This study is significantly important for investigating the effects of intense UWB pulses on biological cells. A detailed analysis from the point- of-view of physical understanding the effects of EMP on human tissue is presented. The biological cell of high conductivity i.e. small relaxation time inducing minimum field inside the human body is studied. A detailed picture of electric field and current evolution is demonstrated.
2004-01-01 - Validating the Itanium 2 exception control unit: a unit-level approach	EPIC (explicitly parallel instruction computing) architectures, such as the Intel IA-64 (Itanium), support novel features such as explicit instruction-level parallelism and predicated instructions. While these features promise to make code more efficient, the fact that these new architectural features means that EPIC code is more difficult to analyze than code for more traditional architectures. This paper describes a technique for removing predication instructions from optimized binary programs in a way that is guaranteed to preserve program semantics, thereby and thereby improve the quality of machine emulation for IA-64
2004-01-01 - Field-testing IMPACT EPIC research results in Itanium 2	EPIC (explicitly parallel instruction computing) architectures, such as the Intel IA-64 (Itanium), support novel features such as explicit instruction-level parallelism and predicated instructions. While these features promise to make code more efficient, the fact that these new architectural features means that EPIC code is more difficult to analyze than code for more traditional architectures. This paper describes a technique for removing predication instructions from optimized binary programs in a way that is guaranteed to preserve program semantics, and thereby improve the quality of binary translation for IA-64.
2004-01-01 - Performance modeling of unstructured mesh particle transport computations	The interaction of ultra-wideband pulses propagating on a semiconductor substrate is analysed without solving the charge dynamic equations. This study demonstrates the systematic approach for selecting semiconductor parameters and their significance in the practical design of high speed microstrip interconnects. To our knowledge, this is the first time such a comprehensive and conceptual study of EMP interaction with semiconductor dielectrics has been performed. The comparison of waveforms on single and coupled lines elucidates the mechanisms of pulse distortion on semiconductor substrates. However, the realization of the dielectric relaxation is studied by changing the doping concentrations of the substrate. Moreover, the evolution of currents for different conductivities illustrates the realization of the doping concentration in a semiconductor. Furthermore, the study on layered substrates with different doping concentrations and relative permittivities demonstrates the fidelity of waveforms on the source line and significantly weak coupling to the victim line. This analysis is a first step towards the full-fledged self- consistent simulations of EMP interaction with the physical model of semiconductor devices. A 160 node Itanium II cluster processor has an average 5 hours simulation time in this work.
2003-01-01 - Unscheduling, unpredication, unspeculation: reverse engineering itanium executables	The architectural reference model, a critical tool in microprocessor validation, serves as a gold standard against which a microprocessor is compared. As all validation is performed using it, the reference model must be timely, extensible beyond the original specification, customizable for specific usage models, and, most importantly, functionally flawless. Ideally, we would like a specification-based design flow that transforms the published English language specifications into compilable code that is directly incorporated into the reference model without loss of information or accuracy. At Intel, we have developed and implemented such a flow to create the Itanium Processor Family's (IPF) reference model, which is used to validate all IPF processors. In this paper, we describe the benefits and limitations of this process and discuss the practical implications of specification-based design.
2004-01-01 - Clock generation and distribution for the 130-nm Itanium/sup /spl reg// 2 processor with 6-MB on-die L3 cache	To improve performance and reduce power, processor designers employ advances that shrink feature sizes, lower voltage levels, reduce noise margins, and increase clock rates. However, these advances make processors more susceptible to transient faults that can affect correctness. While reliable systems typically employ hardware techniques to address soft-errors, software techniques can provide a lower-cost and more flexible alternative. This paper presents a novel, software-only, transient-fault-detection technique, called SWIFT. SWIFT efficiently manages redundancy by reclaiming unused instruction-level resources present during the execution of most programs. SWIFT also provides a high level of protection and performance with an enhanced control-flow checking mechanism. We evaluate an implementation of SWIFT on an Itanium 2 which demonstrates exceptional fault coverage with a reasonable performance cost. Compared to the best known single-threaded approach utilizing an ECC memory system, SWIFT demonstrates a 51% average speedup.
2003-01-01 - A 1.5 GHz third generation Itanium/spl reg/ processor	This paper describes a novel functional Built-in-Self-Test (BIST) method for microprocessors. This technique is based on the fundamental principle that complex chips have embedded functionality that can be used to implement a comprehensive self-test strategy. Functional testing has generally been associated with expensive testers. In order to lower the cost of test, there is a general trend to adopt structural test techniques like scan that enable the use of low cost testers. One of the key advantages of the test method described here is that it enables functional testing of microprocessors on low cost testers. Detailed implementation of this technique, the test generation methodology, the fault grade methodology and silicon results on Intel/sup /spl reg// Pentium/sup /spl reg// 4 and Itanium/spl trade/ family microprocessors are presented.
2003-01-01 - IA-32 execution layer: a two-phase dynamic translator designed to support IA-32 applications on Itanium/spl reg/-based systems	Many scientific programs exchange large quantities of double-precision data between processing nodes and with mass storage devices. Data compression can reduce the number of bytes that need to be transferred and stored. However, data compression is only likely to be employed in high-end computing environments if it does not impede the throughput. This paper describes and evaluates FPC, a fast lossless compression algorithm for linear streams of 64-bit floating-point data. FPC works well on hard-to-compress scientific data sets and meets the throughput demands of high-performance systems. A comparison with five lossless compression schemes, BZIP2, DFCM, FSD, GZIP, and PLMI, on 4 architectures and 13 data sets shows that FPC compresses and decompresses one to two orders of magnitude faster than the other algorithms at the same geometric-mean compression ratio. Moreover, FPC provides a guaranteed throughput as long as the prediction tables fit into the L1 data cache. For example, on a 1.6-GHz Itanium 2 server, the throughput is 670 Mbytes/s regardless of what data are being compressed.
2003-01-01 - The performance of runtime data cache prefetching in a dynamic optimization system	To meet the demands of modern architectures, optimizing compilers must incorporate an ever larger number of increasingly complex transformation algorithms. Since code transformations may often degrade performance or interfere with subsequent transformations, compilers employ predictive heuristics to guide optimizations by predicting their effects a priori. Unfortunately, the unpredictability of optimization interaction and the irregularity of today's wide-issue machines severely limit the accuracy of these heuristics. As a result, compiler writers may temper high variance optimizations with overly conservative heuristics or may exclude these optimizations entirely. While this process results in a compiler capable of generating good average code quality across the target benchmark set, it is at the cost of missed optimization opportunities in individual code segments. To replace predictive heuristics, researchers have proposed compilers which explore many optimization options, selecting the best one a posteriori. Unfortunately, these existing iterative compilation techniques are not practical for reasons of compile time and applicability. We present the Optimization-Space Exploration (OSE) compiler organization, the first practical iterative compilation strategy applicable to optimizations in general-purpose compilers. Instead of replacing predictive heuristics, OSE uses the compiler writer's knowledge encoded in the heuristics to select a small number of promising optimization alternatives for a given code segment. Compile time is limited by evaluating only these alternatives for hot code segments using a general compile-time performance estimator An OSE-enhanced version of Intel's highly-tuned, aggressively optimizing production compiler for IA-64 yields a significant performance improvement, more than 20% in some cases, on Itanium for SPEC codes.
2003-01-01 - A 1.5-GHz 130-nm Itanium/sup /spl reg// 2 Processor with 6-MB on-die L3 cache	The McKinley processor is the result of a joint design effort between Intel and Hewlett-Packard engineers, and is the second processor implementation of the Itanium/sup TM/ Processor Family. This paper describes in detail the processes and methodology developed for debugging a complex and challenging microprocessor design. An overview of microprocessor debug techniques utilized by HP and Intel is presented, followed by descriptions of debug techniques employed on McKinley. Two case studies of electrical bugs encountered during design debug are presented to demonstrate some of the processes and techniques described previously, and results are discussed.
2003-01-01 - A 400-MT/s 6.4-GB/s multiprocessor bus interface	This paper explores Speculative Precomputation, a technique that uses idle thread contexts in a multithreaded architecture to improve performance of single-threaded applications. It attacks program stalls from data cache misses by pre-computing future memory accesses in available thread contexts, and prefetching these data. This technique is evaluated by simulating the performance of a research processor based on the Itanium/sup TM/ ISA supporting Simultaneous Multithreading. Two primary forms of Speculative Precomputation are evaluated. If only the non-speculative thread spawns speculative threads, performance gains of up to 30% are achieved when assuming ideal hardware. However, this speedup drops considerably with more realistic hardware assumptions. Permitting speculative threads to directly spawn additional speculative threads reduces the overhead associated with spawning threads and enables significantly more aggressive speculation, overcoming this limitation. Even with realistic costs for spawning threads, speedups as high as 169% are achieved, with an average speedup of 76%.
2003-01-01 - Unspeculation	Accurate clock skew budgets are important for microprocessor designers to avoid hold-time failures and to properly allocate resources when optimizing global and local paths. Many published clock skew budgets neglect voltage jitter and process variation, which are becoming dominant factors in otherwise balanced H-trees. However, worst-case process variation assumptions are severely pessimistic. This paper describes the major sources of clock skew in a microprocessor using a modified H-tree and applies the model to a second-generation Itanium-M processor family microprocessor currently under design. Monte Carlo simulation is used to develop statistical clock skew budgets for setup and hold time constraints in a four-level skew hierarchy. Voltage jitter through the phase locked loop (PLL) and clock buffers accounts for the majority of skew budgets. We show that taking into account the number of nearly critical paths between clocked elements at each level of the skew hierarchy and variations in the data delays of these paths reduces the difference between global and local skew budgets by more than a factor of two. Another insight is that data path delay variability limits the potential cycle-time benefits of active deskew circuits because the paths with the worst skew are unlikely to also be the paths with the longest data delays.
2003-01-01 - Dragon: an Open64-based interactive program analysis tool for large applications	We present an auto-tuning approach to optimize application performance on emerging multicore architectures. The methodology extends the idea of search-based performance optimizations, popular in linear algebra and FFT libraries, to application-specific computational kernels. Our work applies this strategy to a lattice Boltzmann application (LBMHD) that historically has made poor use of scalar microprocessors due to its complex data structures and memory access patterns. We explore one of the broadest sets of multicore architectures in the HPC literature, including the Intel Clovertown, AMD Opteron X2, Sun Niagara!, STI Cell, as well as the single core Intel Itanium.2. Rather than hand-tuning LBMHD for each system, we develop a code generator that allows us identify a highly optimized version for each platform, while amortizing the human programming effort. Results show that our auto- tuned LBMHD application achieves up to a 14times improvement compared with the original code. Additionally, we present detailed analysis of each optimization, which reveal surprising hardware bottlenecks and software challenges for future multicore systems and applications.
2003-01-01 - Efficient resource management during instruction scheduling for the EPIC architectures	This paper describes the experience of applying agile approaches to the development of firmware for the Intel/spl reg/ Itanium/spl reg/ processor family. Embedded development (i.e. firmware) projects are quite different from object-oriented and pure software endeavors, yet they face many of the same challenges that agile software development practices address. Several unique challenges are described, including team members' specialized domain knowledge, technical backgrounds and attitudes toward change, and the impact hardware plays in firmware design. We found agile approaches to be well-suited for our project, despite the fact that most agile methodologists come from very different backgrounds.
2003-01-01 - The fallacy of spec-based design	Many automatic algorithms have been proposed for analyzing magnetic resonance imaging (MRI) data sets. With the increasingly large data sets being used in brain mapping, there has been a significant rise in the need for accelerating these algorithms. Partial volume estimation (PVE), a brain tissue classification algorithm for MRI, was implemented on a field-programmable gate array (FPGA)-based high performance reconfigurable computer using the Mitrion-C high-level language (HLL). This work develops on prior work in which we conducted initial studies on accelerating the prior information estimation algorithm. In this paper, we extend the work to include probability density estimation and present new results and additional analysis. We used several simulated and real human brain MR images to evaluate the accuracy and performance improvement of the proposed algorithm. The FPGA-based probability density estimation and prior information estimation implementation achieved an average speedup over an Itanium 2 CPU of 2.5times and 9.4times, respectively. The overall performance improvement of the FPGA-based PVE algorithm was 5.1times with four FPGAs.
2002-01-01 - Comparing and contrasting a commercial OLTP workload with CPU2000 on IPF	In a recent invited paper in the IEEE Antennas and Propagation Magazine, some of the challenging problems in computational electromagnetics were presented. One of the objectives of this note is to simply point out that challenging to one may be simple to another. This is demonstrated through an example cited in that article. The example chosen is a Vivaldi antenna array. What we discuss here also applies to the other examples presented in that article, but we have chosen the Vivaldi antenna array to help us make our point. It is shown in this short article that a higher-order basis using a surface integral equation a la a PMCHWT (Poggio-Miller-Chu-Harrington-Wu-Tsai) method-of-moments formulation may still be the best weapon that one have in today's arsenal to deal with challenging complex electromagnetic analysis problems. Here, we have used the commercially available code WIPL-D to carry out all the computations using laptop/desktop systems. The second objective of this paper is to present an out-of-core solver. The goal is to demonstrate that an out-of-core 32-bit-system-based solver can be as efficient as a 64-bit in-core solver. This is quite contrary to the popular belief that an out-of-core solver is generally much slower than an in-core solver. This can be significant, as the difference in the cost of a 32-bit system can be 1/30 of a 64-bit system of similar capabilities using current computer architectures. For the 32-bit system, we consider a Pentium 4 system, whereas for the 64-bit system, we consider an Itanium 2 system for comparison. The out-of-core solver can go beyond the 2 GB limitation for a 32-bit system and can be run on ordinary laptop/desktop; hence, we can simultaneously have a much lower hardware investment while better performance for a sophisticated and powerful electromagnetic solver. The system resources and the CPU times are also outlined.
2003-01-01 - Clock generation and distribution for the third generation Itanium/spl reg/ processor	This paper proposes and evaluates hardware mechanisms for supporting prescient instruction prefetch â€” an approach to improving single-threaded application performance by using helper threads to perform instruction prefetch. We demonstrate the need for enabling store-to-load communication and selective instruction execution when directly pre-executing future regions of an application that suffer I-cache misses. Two novel hardware mechanisms, safe-store and YAT-bits, are introduced that help satisfy these requirements. This paper also proposes and evaluates .nite state machine recall, a technique for limiting pre-execution to branches that are hard to predict by leveraging a counted I-prefetch mechanism. On a research ItaniumÂ®SMT processor with next line and streaming I-prefetch mechanisms that incurs latencies representative of next generation processors, prescient instruction prefetch can improve performance by an average of 10.0% to 22% on a set of SPEC 2000 benchmarks that suffer significant I-cache misses. Prescient instruction prefetch is found to be competitive against even the most aggressive research hardware instruction prefetch technique: fetch directed instruction prefetch.
2003-01-01 - A 1.5GHz third generation Itanium 2 processor	To achieve higher processor performance requires greater synergy between advanced hardware features and innovative compiler techniques. Recent advancement in compilation techniques for predicated execution has provided significant opportunity in exploiting instruction level parallelism. However, little research has been done on how to efficiently execute predicated code in a dynamic microarchitecture. In this paper, we evaluate hardware optimizations for executing predicated code on a dynamically scheduled microarchitecture. We provide two novel ideas to improve the efficiency of executing predicated code. On a generic Intel Itanium processor pipeline model, we demonstrate that, with some microarchitecture enhancements, a dynamic execution processor can achieve about 16% performance improvement over an equivalent static execution processor.
2003-01-01 - Compiler and runtime support for running OpenMP programs on Pentium- and Itanium-architectures	Integer division on modern processors is expensive compared to multiplication. Previous algorithms for performing unsigned division by an invariant divisor, via reciprocal approximation, suffer in the worst case from a common requirement for n+1 bit multiplication, which typically must be synthesized from n-bit multiplication and extra arithmetic operations. This paper presents, and proves, a hybrid of previous algorithms that replaces n+1 bit multiplication with a single fused multiply-add operation on n-bit operands, thus reducing any n-bit unsigned division to the upper n bits of a multiply-add, followed by a single right shift. An additional benefit is that the prerequisite calculations are simple and fast. On the Itanium/spl reg/ 2 processor, the technique is advantageous for as few as two quotients that share a common run-time divisor.
2003-01-01 - A statistical adaptive block-matching motion estimation	Traditional software controlled data cache prefetching is often ineffective due to the lack of runtime cache miss and miss address information. To overcome this limitation, we implement runtime data cache prefetching in the dynamic optimization system ADORE (ADaptive Object code Reoptimization). Its performance has been compared with static software prefetching on the SPEC2000 benchmark suite. Runtime cache prefetching shows better performance. On an Itanium 2 based Linux workstation, it can increase performance by more than 20% over static prefetching on some benchmarks. For benchmarks that do not benefit from prefetching, the runtime optimization system adds only 1%-2% overhead. We have also collected cache miss profiles to guide static data cache prefetching in the ORC compiler. With that information the compiler can effectively avoid generating prefetches for loops that hit well in the data cache.
2003-01-01 - Itanium 2 processor microarchitecture	Optimizing programs at run-time provides opportunities to apply aggressive optimizations to programs based on information that was not available at compile time. At run time, programs can be adapted to better exploit architectural features, optimize the use of dynamic libraries, and simplify code based on run-time constants. Our profiling system provides a framework for collecting information required for performing run-time optimization. We sample the performance hardware registers available on an Itanium processor, and select a set of code that is likely to lead to important performance-events. We gather distribution information about the performance-events we wish to monitor, and test our traces by estimating the ability for dynamic patching of a program to execute run-time generated traces. Our results show that we are able to capture 58% of execution time across various SPEC2000 integer benchmarks using our profile and patching techniques on a relatively small number of frequently executed execution paths. Our profiling and detection system overhead increases execution time by only 2-4%.
2003-01-01 - Compiler and runtime support for running OpenMP programs on Pentium- and Itanium-architectures	Processor speed continues to increase faster than the speed of access to main memory, making effective use of memory caches more important. Information about an applicationâ€™s interaction with the cache is therefore critical to performance tuning. To be most useful, tools that measure this information should relate it to the source code level data structures in an application. We describe how to gather such information by using hardware performance counters to sample cache miss addresses, and present a new tool named Cache Scope that does this using the Intel Itanium 2 performance monitors. We present experimental results concerning Cache Scopeâ€™s accuracy and perturbation of cache behavior. We also describe a case study of using Cache Scope to tune two applications, achieving 24% and 19% reductions in running time.
2003-01-01 - A region-based compilation infrastructure	The McKinley processor is the result of a joint design effort between Intel and Hewlett-Packard engineers, and is the second processor implementation of the Itanium/sup TM/ processor family (IPF) architecture. This paper describes the methodology developed for testing a complex high-performance microprocessor design. An overview of the processor is presented, along with the goals for the test methodology. Details of the test control blocks, scan methodology, and clocking are given. The scanlatch design, trade-offs and verification processes are discussed, along with some details of ATPG modeling and memory array testing. Finally, some results are presented.
2003-01-01 - Procedure cloning and integration for converting parallelism from coarse to fine grain	In this paper we introduce a new concept, network atomic operations (NAOs) to create a zero-cost consistent cut. Using NAOs, we define a wall-clock-time driven GVT algorithm called Seven O'Clock that is an extension of Fujimoto's shared memory GVT algorithm. Using this new GVT algorithm, we report good optimistic parallel performance on a cluster of state-of-the-art Itanium-II quad processor systems for both benchmark applications such as PHOLD and real-world applications such as a large-scale TCP/Internet model. In some cases, super-linear speedup is observed.
2003-01-01 - Optimization for the Intel/spl reg/ Itanium/spl reg/ architecture register stack	Disk arrays provide data storage by combining sets of disks into one or more virtual disks (VDs) utilizing specialized control algorithms. A VD is a partition of such combined storage capacity perceived by the user as a physical disk. VD cloning is a data protection technique that copies the data from one VD to another. A typical problem with VD cloning is that it delays user reads and writes, i.e., increases response times. This paper presents VD- Interval Type 2 (IT2), an effective IT2 fuzzy logic control (IT2 FLC) approach to VD cloning that dramatically reduces the response time delay. The VD-IT2 cloning scheme is capable of balancing two adversely affecting processes: VD cloning and user read/write response times. This IT2 FLC-based approach regulates throughput of VD cloning with regards to the user request activity. The VD-IT2 solves the increased delay in user reads and write during cloning by adjusting the time interval between cloning requests. The contribution of this paper is two-fold. First, a novel formula for planning of data backups is presented. The data backup formula predicts the fraction of replicated data blocks in a combined (clone and snap) replication. Second, a novel IT2 FLC scheme reduces response time of user reads/writes in half. The VD-IT2 was tested on an Itanium workstation with 120 disks and proved 50% reduction of user latencies within a short period of time (high response time of 60 ms was reduced to half, within 30 s only), on an average basis.
2003-01-01 - Optimizations to prevent cache penalties for the Intel/spl reg/ Itanium/spl reg/ 2 processor	This paper describes the design of a system bus interface for the 130-nm Itanium/sup /spl reg//2 processor that operates at 400MT/s (1 megatransfer = 1 Mb/s/pin) with a peak bandwidth of 6.4 GB/s. The high-speed operation is achieved by employing source-synchronous transfer with differential strobes. Short flight time is accomplished by double-sided placement of the processors. Preboost and postboost edge-rate control enables fast clock-to-output timing with tight edge-rate range. The built-in input/output (I/O) loopback test feature enables I/O parameters to be tested on die, using a delay-locked loop and interpolator with 21-ps phase-skew error and 15-ps rms jitter. Power modeling methodology facilitates accurate prediction of system performance.
2003-01-01 - Inlining of mathematical functions in HP-UX for Itanium/sup /spl reg// 2	Since the introduction of the Fused Multiply and Add (FMA) in the IEEE-754-2008 standard for floatingpoint arithmetic, division based on Newton-Raphson's iterations becomes a viable alternative to SRT-based divisions. The Newton-Raphson iterations were already used in some architecture prior to the revision of the IEEE-754 norm. For example, Itanium architecture already used this kind of iterations. Unfortunately, the proofs of the correctness of binary algorithms do not extend to the case of decimal floating-point arithmetic. In this paper, we present general methods to prove the correct rounding of division algorithms using Newton-Raphson's iterations in software, for radix 2 and radix 10 floating-point arithmetic.
2003-01-01 - Compiler optimization-space exploration	Despite its current popularity, para-virtualization has an enormous cost. Its deviation from the platform architecture abandons many of the benefits of traditional virtualization: stable and well-defined platform interfaces, hypervisor neutrality, operating system neutrality, and upgrade neutrality - in sum, modularity. Additionally, para-virtualization has a significant engineering cost. These limitations are accepted as inevitable for significantly better performance, and for the ability to provide virtualization-like behavior on non-virtualizable hardware such as times86. Virtualization and its modularity solve many systems problems, and when combined with the performance of para-virtualization become even more compelling. We show how to achieve both together. We still modify the guest operating system, but according to a set of design principles that avoids lock-in, which we call soft layering. Additionally, our approach is highly automated and thus reduces the implementation and maintenance burden of paravirtualization, which is especially useful for enabling obsoleted operating systems. We demonstrate soft layering on times86 and itanium: we can load a single Linux binary on a variety of hypervisors (and thus substitute virtual machine environments and their enhancements), while achieving essentially the same performance as para-virtualization with less effort.
2003-01-01 - Dynamic trace selection using performance monitoring hardware sampling	Software data prefetching is a well-known technique to improve the performance of programs that suffer many cache misses at several levels of memory hierarchy. However, it has significant overhead in terms of increased code size, additional instructions, and possibly increased memory bus traffic due to redundant prefetches. This paper presents two novel methods to reduce the overhead of software data prefetching and improve the program performance by optimized prefetch scheduling. These methods exploit the availability of rotating registers and predication in architectures such as the Itanium/sup TM/ architecture. The methods (I) minimize redundant prefetches, (2) reduce the number of issue slots needed for prefetch instructions, and (3) avoid branch mispredict penalties - all with minimal code size increase. Compared to traditional data prefetching techniques, these methods (i) do not require loop unrolling, (ii) do not require predicate computations and (iii) require fewer machine resources. One of these methods has been implemented in the Intel Production Compiler for the ItaniumTM processor. This technique is compared with traditional approaches for software prefetching and experimental results are presented based on the floating-point benchmark suite of CPU2000.
2003-01-01 - Integrated prepass scheduling for a Java just-in-time compiler on the IA-64	We address the problem of motion estimation (ME) in digital video sequences and propose a new fast, adaptive, and efficient block-matching algorithm. Higher quality and efficiency are achieved using a statistical model for the motion vectors. This model introduces adaptation in the search window, drastically reducing the number of positions where correlation-type computation is performed. The efficiency is further improved by progressively undersampling the macroblock. Patterns for undersampling are proposed to obtain the maximum benefit from single instruction multiple data (SIMD) instructions. In contrast with existing motion-estimation techniques, search strategy and subsampled patterns are closely linked. This shows that a good search strategy is much more important than blindly reducing the number of pixels considered for the matching pattern. We describe an implementation of the proposed matching strategy that exploits the very long instruction word (VLIW) and SIMD technology available in the new Itanium processor family. Results show that the proposed algorithm adapts easily to the evolution of the scene avoiding annoying quality drops that can be observed with other deterministic algorithms. The total number of operations required by the proposed method is inferior to those required by traditional approaches.
2003-01-01 - Performance potentials of compiler-directed data speculation	Presented is a method for debugging of pipelined processors in their formal verification with the highly automatic and scalable approach of Correspondence Checking, where a pipelined/superscalar/VLIW implementation is compared against a non-pipelined specification via an inductive correctness criterion based on symbolic simulation in a way that guarantees the correctness of the implementation for all possible execution scenarios. The benefit from the proposed method increases with the complexity of the processor under formal verification. For a 12-stage VLIW processor that imitates the Intel Itanium in many features, the method reduced the size of the EUFM correctness formulas from buggy processors by up to an order of magnitude, the number of Boolean variables in the equivalent propositional correctness formulas and the number of 1s in the counterexample traces by up to 2 orders of magnitude, and resulted in an average speedup in detecting the bugs of 2 orders of magnitude, thus increasing the productivity of the processor designers.
2002-01-01 - Data Cache design considerations for the Itanium/sub /spl reg// 2 Processor	Total order broadcast is a fundamental communication primitive that plays a central role in bringing cheap software-based high availability to a wide array of services. This paper studies the practical performance of such a primitive on a cluster of homogeneous machines. We present FSR, a (uniform) total order broadcast protocol that provides high throughput, regardless of message broadcast patterns. FSR is based on a ring topology, only relies on point-to-point inter-process communication, and has a linear latency with respect to the total number of processes in the system. Moreover, it is fair in the sense that each process has an equal opportunity of having its messages delivered by all processes. On a cluster of Itanium based machines, FSR achieves a throughput of 79 Mbit/s on a 100 Mbit/s switched Ethernet network
2002-01-01 - Just-in-time Java compilation for the Itanium/spl reg/ processor	Smaller input data sets such as the test and the train input sets are commonly used in simulation to estimate the impact of architecture/micro-architecture features on the performance of SPEC benchmarks. They are also used for profile feedback compiler optimizations. In this paper, we examine the reliability of reduced input sets for performance simulation and profile feedback optimizations. We study the high level metrics such as IPC and procedure level profiles as well as lower level measurements such as execution paths exercised by various input sets on the SPEC2000int benchmark. Our study indicates that the test input sets are not suitable to be used for simulation because they do not have an execution profile similar to the reference input runs. The train data set is better than the test data sets at maintaining similar profiles to the reference input set. However, the observed execution paths leading to cache misses are very different between using the smaller input sets and the reference input sets. For current profile based optimizations, the differences in quality of profiles may not have a significant impact on performance, as tested on the Itanium processor with an Intel compiler. However, we believe the impact of profile quality will be greater for more aggressive profile guided optimizations, such as cache prefetching.
2002-01-01 - Power-performance trade-offs for energy-efficient architectures: A quantitative study	We introduce an algorithm for multiplying a floating-point number x by a constant C that is not exactly representable in floating-point arithmetic. Our algorithm uses a multiplication and a fused multiply and add instruction. Such instructions are available in some modern processors such as the IBM Power PC and the Intel/HP Itanium. We give three methods for checking whether, for a given value of C and a given floating-point format, our algorithm returns a correctly rounded result for any x. When it does not, some of our methods return all of the values x for which the algorithm fails. The three methods are complementary: The first two do not always allow one to conclude, yet they are simple enough to be used at compile time, while the third one always either proves that our algorithm returns a correctly rounded result for any x or gives all of the counterexamples. We generalize our study to the case where a wider internal format is used for the intermediate calculations, which gives a fourth method. Our programs and some additional information (such as the case where an arbitrary nonbinary even radix is used), as well as examples of runs of our programs, can be downloaded from http://perso.ens-lyon.fr/iean-michel.muller/MultConstant.html.
2002-01-01 - Eliminating exception constraints of Java programs for IA-64	Performing analysis across module boundaries for an entire program is important for exploiting several runtime performance opportunities. However, due to scalability problems in existing full-program analysis frameworks, such performance opportunities are only realized by paying tremendous compile-time costs. Alternative solutions, such as partial compilations or user assertions, are complicated or unsafe and as a result, not many commercial applications are compiled today with cross-module optimizations. We present SYZYGY, a practical framework for performing efficient, scalable, interprocedural optimizations. The framework is implemented in the HP-UX Itanium/spl reg/ compilers and we have successfully compiled many very large applications consisting of millions of lines of code. We achieved performance improvements of up to 40% over optimization level two and compilation time improvements in the order of 100% and more compared to a previous approach.
2002-01-01 - A fully bypassed six-issue integer datapath and register file on the Itanium-2 microprocessor	While compilers have generally proven adept at planning useful static instruction-level parallelism for in-order microarchitectures, the efficient accommodation of unanticipateable latencies, like those of load instructions, remains a vexing problem. Traditional out-of-order execution hides some of these latencies, but repeats scheduling work already done by the compiler and adds additional pipeline overhead. Other techniques, such as prefetching and multithreading, can hide some anticipateable, long-latency misses, but not the shorter, more diffuse stalls due to difficult-to-anticipate, first or second-level misses. Our work proposes a microarchitectural technique, two-pass pipelining, whereby the program executes on two in-order back-end pipelines coupled by a queue. The "advance" pipeline often defers instructions dispatching with unready operands rather than stalling. The "backup" pipeline allows concurrent resolution of instructions deferred by the first pipeline allowing overlapping of useful "advanced" execution with miss resolution. An accompanying compiler technique and instruction marking further enhance the handling of miss latencies. Applying our technique to an Itanium 2-like design achieves a speedup of 1.38x in mcf, the most memory-intensive SPECint2000 benchmark, and an average of 1.12 x across other selected benchmarks, yielding between 32 percent and 67 percent of an idealized out-of-order design's speedup at a much lower design cost and complexity.
2002-01-01 - The on-chip 3-MB subarray-based third-level cache on an Itanium microprocessor	Performance evaluation of contemporary processors is becoming increasingly difficult due to the lack of proper frameworks. Traditionally, cycle-accurate simulators have been extensively used due to their inherent accuracy and flexibility. However, the effort involved in building them, their slow speed, and their limited ability to provide insight often imposes constraints on the extent of design exploration. In this paper, we refine our earlier Monte Carlo based CPI prediction model (Srinivasan et al., 2006) to include software assisted data-prefetching and an improved memory model. Software-based prefetching is becoming an increasingly important feature in modern processors but to the best of our knowledge, existing frameworks do not model it. Our model uses micro-architecture independent application characteristics to predict CPI with an average error of less than 10% when validated against the Itanium-2 processor. Besides accurate performance prediction, we illustrate the applications of the model to processor bottleneck analysis, workload characterization and design space exploration
2002-01-01 - The implementation of the Itanium 2 microprocessor	64-bit processor architectures like the Intel/spl reg/ Itanium/spl reg/ processor family are designed for large applications that need large memory addresses. When running applications that fit within a 32-bit address space, 64-bit CPUs are at a disadvantage compared to 32-bit CPUs because of the larger memory footprints for their data. This results in worse cache and TLB utilization, and consequently lower performance because of increased miss ratios. This paper considers software techniques for virtual machines that allow 32-bit pointers to be used on 64-bit CPUs for managed runtime applications that do not need the full 64-bit address space. We describe our pointer compression techniques and discuss our experience implementing these for Java applications. In addition, we give performance results with our techniques for both the SPEC JVM98 and SPEC JBB2000 benchmarks. We demonstrate a 12% performance improvement on SPEC JBB2000 and a reduction in the number of garbage collections required for a given heap size.
2002-01-01 - Scalability port: a coherent interface for shared memory multiprocessors	Thread migration moves a single call-stack to another machine to improve either load balancing or locality. Current approaches for checkpointing and thread migration are either not heterogeneous or they introduce large runtime overhead. In general, previous approaches add overhead by instrumenting each function in a program. The instrumentation costs are then even incurred when no thread migration is performed. In this respect our system is near-overhead free: nearly no overhead is caused if no migration is performed. Our implementation instead generates meta-functions for each location in the code where a function is called. These functions portably save and rebuild activation records to and from a machine-independent format. Each variable of an activation record is described in terms of its usages in a machine-independent `usage descriptor string' to enable heterogeneous, near overhead free thread migration with as few as possible changes to a compiler. Our resulting thread migration solution is, for example, able to move a thread between an x86 machine (few registers, 32 bits) and an Itanium machine (many registers, 64 bits). Furthermore, we (optionally) move the decision on when and where to migrate to the application programmer instead of implementing a fixed 'fits-all' heuristics as in previous approaches
2002-01-01 - FRITS - a microprocessor functional BIST method	Even with the breakthroughs in semiconductor technology that enables billion transistor designs, hardware-based architecture paradigms alone cannot substantially improve processor performance. The challenge in realizing the full potential of these future machines is to find ways to adapt program behavior to application needs and processor resources. As such, run-time optimization has a distinct role in future high performance systems. However, as these systems are dependent on accurate, fine-grain profile information, traditional approaches to collecting profiles at run-time result in significant slowdowns during program execution. A novel approach to low-overhead profiling is to exploit hardware performance monitoring units (PMUs) present in modern microprocessors. The Itanium-2 PMU can periodically sample the last few taken branches in an executing program and this information can be used to recreate partial paths of execution. With compiler-aided analysis, the partial paths can be correlated into full paths. As statistically hot paths are most likely to occur in PMU samples, even infrequent sampling can accurately identify these paths. While traditional path profiling techniques carry a high overhead, a PMU-based path profiler represents an effective lightweight profiling alternative. This paper characterizes the PMU-based path information and demonstrates the construction of such a PMU-based path profiler for a run-time system.
2001-01-01 - The IA-64 Itanium processor cartridge	Stream processors, developed for the stream programming model, perform well on media applications. In this paper we examine the applicability of a stream processor to scientific computing applications. Eight scientific applications, each having different performance characteristics, are mapped to a stream processor. Due to the novelty of the stream programming model, we show how to map programs in a traditional language, such as FORTRAN. In a stream processor system, the management of system resources is the programmers' responsibility. We present several optimizations, which enable mapped programs to exploit various aspects of the stream processor architecture. Finally, we analyze the performance of the stream processor and the presented optimizations on a set of scientific computing applications. The stream programs are from 1.67 to 32.5 times faster than the corresponding FORTRAN programs on an Itanium 2 processor, with the optimizations playing an important role in realizing the performance improvement.
2002-01-01 - Packaging the Itanium/spl reg/ microprocessor	Research on procedure inlining has mainly focused on heuristics that decide whether inlining a particular call-site maximizes application performance. However, other equally important aspects of inline analysis such as call-site analysis order, indirect effects of inlining, and selection of the most profitable version of a procedure warrant more attention. This paper evaluates a number of different sequences in which call-sites are examined for inlining and shows that choosing the correct order is crucial to obtaining the best run-time performance. We then present a novel, work-list-based, and updated sequence that achieves the best results. While applying cross-module inline analysis on large applications with thousands of files and millions of lines of code, we separate the analysis from the transformation phase and allow the former to work solely on summary information in order to reduce compile-time and memory consumption. A focus of this paper is to enumerate the summaries that our compiler maintains, present a technique to compute the goodness factor on which the work-list sequence is based, and describe methods to continuously update the summaries as and when a call-site is accepted for inlining. We then introduce inline specialization, a new technique that facilitates inlining into call chains selectively. The power of inline specialization lies in its ability to choose the most profitable version of the called procedure without having to maintain multiple versions at any point of time. We discuss implementation of these techniques in the HPUX Itanium/spl reg/ production compiler and present experimental results showing that a dynamic work-list based analysis order, comprehensive summary updates, and inline specialization significantly improve performance of applications.
2002-01-01 - The implementation of the next-generation 64 b Itanium/sup TM/ microprocessor	This paper presents COBRA (continuous binary re-adaptation), a runtime binary optimization framework, for multithreaded applications. It is currently implemented on Itanium 2 based SMP and cc-NUMA systems. Using OpenMP NAS parallel benchmark, we show how COBRA can adoptively choose appropriate optimizations according to observed changing runtime program behavior. Coherent cache misses caused by true/false data sharing often limit the scalability of multithreaded applications. This paper shows that COBRA can significantly improve the performance of some applications parallelized with OpenMP, by reducing the aggressiveness of data prefetching and by using exclusive hints for prefetch instructions. For example, we show that COBRA can improve the performance of OpenMP NAS parallel benchmarks up to 68%, with an average of 17.5% on the SGI Altix cc-NUMA system.
2001-01-01 - Towards a formal model of shared memory consistency for Intel Itanium/sup TM/	A program analysis tool can play an important role in helping users understand and improve large application codes. Dragon is a robust interactive program analysis tool based on the Open64 compiler, which is an Open source C/C++/Fortran77/90 compiler for Intel Itanium systems. We designed and developed the Dragon analysis tool to support manual optimization and parallelization of large applications by exploiting the powerful analyses of the Open64 compiler. Dragon enables users to visualize and print the essential program structure of and obtains information on their large applications. Current features include the call graph, flow graph, and data dependences. Ongoing work extends both Open64 and Dragon by a new call graph construction algorithm and its related interprocedural analysis, global variable definition and usage analysis, and an external interface that can be used by other tools such as profilers and debuggers to share program analysis information. Future work includes supporting the creation and optimization of shared memory parallel programs written using OpenMP.
2002-01-01 - The high-bandwidth 256 kB 2nd level cache on an Itanium microprocessor	Memory disambiguation mechanisms, coupled with load/store queues in out-of-order processors, are crucial to increase instruction level parallelism (ILP), especially for memory-bound scientific codes. Designing ideal memory disambiguation mechanisms is too complex because it would require precise address bits comparators; thus, modern microprocessors implement simplified and imprecise ones that perform only partial address comparisons. In this paper, we study the impact of such simplifications on the sustained performance of some real processors such that Alpha 21264, Power 4 and Itanium 2. Despite all the advanced features of these processors, we demonstrate in this article that memory address disambiguation mechanisms can cause significant performance loss. We demonstrate that, even if data are located in low cache levels and enough ILP exist, the performance degradation can be up to 21 times slower if no care is taken on the order of accessing independent memory addresses. Instead of proposing a hardware solution to improve load/store queues, as done in [G. Chrysos et al., (1998), S. Sethumadhavan et al., (2003), I. Park et al., (2003), A. Yoaz et al., (1999), S. Onder (2002)], we show that a software (compilation) technique is possible. Such solution is based on the classical (and robust) Id/st vectorization. Our experiments highlight the effectiveness of such method on BLAS 1 codes that are representative of vector scientific loops.
2001-01-01 - Itanium/sup TM/ Processor system bus design	Comprehensive transition scan content was deployed on an IntelÂ® ItaniumÂ® server microprocessor design, including full coverage patterns for all core logic blocks. Since this was the first time at-speed scan patterns were being planned as a manufacturing screen on an IntelÂ® CPU core design, the test deployment team needed to ensure that all concerns of over-and under-testing were systematically addressed. A few innovative and novel DFT solutions were deployed to ensure that the post-silicon team had the adequate tools to fully analyze the at-speed scan content. This paper describes these DFT solutions that proved invaluable during this process.
2002-01-01 - The 16 kB single-cycle read access cache on a next-generation 64 b Itanium microprocessor	With the complexity of contemporary single- and multi-core, multi-threaded processors comes a greater need for faster methods of performance analysis and design. It is no longer practical to use only cycle-accurate processor simulators for design space analysis of modern processors and systems. Therefore, we propose a statistical processor modeling method that is based on Monte Carlo techniques. In this paper, we present new details of the methodology and the recent extensions that we have made to it, including the capability to model multi-core processors. We detail the steps to develop a new model and then present statistical performance models of the Sun Niagara 2 processor micro-architecture that, together with a previously published Itanium 2 Monte Carlo model, demonstrates the validity of the technique and its new capabilities. We show that we can accurately predict single and multi-core performance within 7% of actual on average, and we can use the models to quickly pinpoint performance problems at various components.
2002-01-01 - The implementation of the next-generation 64b itanium microprocessor	The increasing complexity of hardware features for recent processors makes high performance code generation very challenging. In particular, several optimization targets have to be pursued simultaneously (minimizing L1/L2/L3/TLB misses and maximizing instruction level parallelism). Very often, these optimization goals impose different and contradictory constraints on the transformations to be applied. We propose a new hierarchical compilation approach for the generation of high performance code relying on the use of state-of-the-art compilers. This approach is not application-dependent and do not require any assembly hand-coding. It relies on the decomposition of the original loop nest into simpler kernels, typically 1D to 2D loops, much simpler to optimize. We successfully applied this approach to optimize dense matrix muliply primitives (not only for the square case but to the more general rectangular cases) and convolution. The performance of the optimized codes on Itanium 2 and Pentium 4 architectures outperforms ATLAS and in most cases, matches hand-tuned vendor libraries (e.g. MKL)
2002-01-01 - The core clock system on the next generation Itanium/spl trade/ microprocessor	Summary form only given. The performance of unstructured mesh applications presents a number of complexities and subtleties that do not arise for dense structured meshes. From a programming point of view, handling an unstructured mesh has an increased complexity to manage the necessary data structures and interactions between mesh-cells. From a performance point of view, there are added difficulties in understanding both the processing time on a single processor and the scaling characteristics. Here we present a performance model for the calculation of deterministic S/sub N/ transport on unstructured meshes. It builds upon earlier work that successfully modeled the same calculation on structured meshes. The model captures the key processing characteristics and is parametric using both the system performance data (latency, bandwidth, processing rate etc.) and application data (mesh size etc.) as input. The model is validated on two clusters (an HP AlphaServer and an Itanium-2 system) showing high accuracy. Importantly it is also shown that a single formulation of the model can be used to predict the performance of two quite different implementations of the same calculation.
2002-01-01 - The on-chip 3 MB subarray based 3rd level cache on an Itanium microprocessor	Modern architectures, such as the Intel Itanium, support speculation, a hardware mechanism that allows the early execution of expensive operations possibly even before it is known whether the results of the operation are needed. While such speculative execution can improve execution performance considerably, it requires a significant amount of complex support code to deal with and recover from speculation failures. This greatly complicates the tasks of understanding and re-engineering speculative code. This paper describes a technique for removing speculative instructions from optimized binary programs in a way that is guaranteed to preserve program semantics, thereby making the resulting "unspeculated" programs easier to understand and more amenable to reengineering using traditional reverse engineering techniques.
2002-01-01 - The 16kB single-cycle read access cache on a next-generation 64b itanium microprocessor	While the concept of online profile directed dynamic optimizations using hardware performance monitoring unit (PMU) data is not new, it has seen fairly limited or no use in commercial JVMs. The main reason behind this fact is the set of significant challenges involved in (1) obtaining low overhead and usable profiling support from the underlying platform (2) the complexity of filtering, interpreting and using precise PMU events online in a JVM environment (3) demonstrating the total runtime benefit of PMU data based optimizations above and beyond regular online profile based optimizations. In this paper we address all three challenges by presenting a practical framework for PMU data collection and use within a high performance product JVM on a highly scalable server platform. Our experiments with JavaTM workloads using the SunTM HotspotTM JDK 1.6 JVM on the Intel Â® Itanium Â® platform indicate that the hardware data collection overhead (less than 0.5%) is not as significant as the challenge of extracting the precise information for optimization purposes. We demonstrate the feasibility of mapping the instruction IP address based hardware event information to the runtime components as well as the JIT server compiler internal data structures for use in optimizations within a dynamic environment. We also evaluated the additional performance potential of optimizations such as object co-location during garbage collection and global instruction scheduling in the JIT compiler with the use of PMU generated load latency information. Experimental results show performance improvements of up to 14%Â Â with an average ofÂ Â 2.2% across select Java server benchmarks such as SPECjbb2005[16], SPECjvm2008[17] and Dacapo[18]. These benefits were observed over and above those provided by profile guided server JVM optimizations in the absence of hardware PMU data.
2002-01-01 - A fully-bypassed 6-issue integer datapath and register file on an Itanium microprocessor	Traditional alias analysis is expensive and ineffective for dynamic optimizations. In practice, dynamic optimization systems perform memory optimizations speculatively, and rely on hardware, such as alias registers, to detect memory aliases at runtime. Existing hardware alias detection schemes either cannot scale up to a large number of alias registers or may introduce false positives. Order-based alias detection overcomes the limitations. However, it brings considerable challenges as how software can efficiently manage the alias register queue and impose restrictions on optimizations. In this paper, we present SMARQ, a Software-Managed Alias Register Queue, which manages the alias register queue efficiently and supports more aggressive speculative optimizations. We conducted experiments with a dynamic optimization system on a VLIW processor that has 64 alias registers. The experiments on a suite of SPECFP2000 benchmarks show that SMARQ improves the overall performance by 39% as compared to the case without hardware alias detection. By scaling up to a large number (from 16 to 64) of alias registers, SMARQ improves performance by 10%. Compared to a technique with false positives (similar to Itanium), SMARQ improves performance by 13%. To reduce the chance of alias register overflow, the novel alias register allocation algorithm in SMARQ reduces the alias register working set by 74% as compared to a straightforward alias register allocation based on program order.
2002-01-01 - An on-chip 3MB subarray-based 3rd level cache on an itanium microprocessor	Java exception checks are designed to ensure that any, faulting instruction causing a hardware exception does not terminate the program abnormally. These checks, however, impose some constraints upon the execution order between an instruction potentially raising a Java exception and a faulting instruction causing a hardware exception. This reduces the effectiveness of instruction reordering optimization. We propose a new framework to effectively perform speculation for the Java language using a direct acyclic graph representation based on the SSA form. Using this framework, we apply a well-known speculation technique to a faulting load instruction to eliminate such constraints. We use edges to represent exception constraints. This allows us to accurately estimate the potential reduction of the critical path length for applying speculation. We also propose an approach to avoid extra copy instructions and to generate efficient code with minimum register pressure. We have implemented the technique in the IBM Java Just-In-Time compiler, and observed performance improvements up to 25% for micro-benchmark programs, up to 10% for Java Grande Benchmark Suite, and up to 12% for SPECjvm98 on an Itanium processor.
2002-01-01 - The high-bandwidth 256kB 2nd-level cache on an itanium microprocessor	In this paper we develop a new region-based compilation framework driven by the considerations of performance opportunities and compilation resources. In addition, we allow some optimization-directed attributes communicated from one optimization phase to another on a region basis to guide subsequent optimizations. This region-based framework has been implemented in the Open Research Compiler targeting Itanium/sup /spl reg// Processor Family (IPF). Experimental results from the SPEC2000Int programs show that this infrastructure provides an effective control on forming regions to meet the requirements of different optimizations. For example, the compilation time of instruction scheduling is significantly reduced by this region formation infrastructure while preserving or improving the overall performance. At the highest optimization level, the performance of one program has a 15.6% improvement by employing this region-based infrastructure.
2002-01-01 - A fully-bypassed 6-issue integer datapath and register file on an itanium microprocessor	With advances in hardware-assisted full virtualization technologies, system virtualization based on the virtual machine monitor (VMM) has received much recent attention. Using the Xen/IA64 hardware virtual machine implemented on IntelÂ® Virtualization Technology for ItaniumÂ® (VT-i), we investigate the design of a virtual software hash translation lookaside buffer (TLB) based on the virtual hash page table (VHPT). Experimental results show that the proposed design can significantly improve the performance of the hardware virtual machine of Xen/IA64. Our contributions are the following. First, we design and implement in the VMM a virtual hash TLB algorithm to optimize the system performance of VT-i guest virtual machines. Second, we quantify experimentally the performance benefits of the hash TLB for VT-i guest virtual machines and analyze the performance impact of the software VHPT walker with the hash TLB algorithm. Lastly, we present experiments to verify, in an SMP virtual machine system environment, the superior scalability of the hash TLB approach.
2002-01-01 - Memory latency-tolerance approaches for Itanium processors: out-of-order execution vs. speculative precomputation	A general framework that integrates both control and data speculation using alias profiling and/or compiler heuristic rules has shown to improve SPEC2000 performance on Itanium systems. However, speculative optimizations require check instructions and recovery code to ensure correct execution when speculation fails at runtime. How to generate check instructions and their associated recovery code efficiently and effectively is an issue yet to be well studied. Also, it is very important that the recovery code generated in the earlier phases integrate gracefully in the later optimization phases. At the very least, it should not hinder later optimizations, thus, ensuring overall performance improvement. This paper proposes a framework that uses an if-block structure to facilitate check instructions and recovery code generation for general speculative optimizations. It allows speculative instructions and their recovery code generated in the early compiler optimization phases to be integrated effectively with the subsequent optimization phases. It also allows multilevel speculation for multilevel pointers and multilevel expression trees to be handled with no additional complexity. The proposed recovery code generation framework has been implemented in the open research compiler (ORC).
2002-01-01 - Quantitative evaluation of the register stack engine and optimizations for future Itanium processors	We present a new integrated prepass scheduling (IPS) algorithm for a Java just-in-time (JIT) compiler which integrates register minimization into list scheduling. We use backtracking in the list scheduling when we have used up all the available registers. To reduce the overhead of backtracking, we incrementally maintain a set of candidate instructions for undoing scheduling. To maximize the ILP after undoing scheduling, we select an instruction chain with the smallest increase in the total execution time. We implemented our new algorithm in a production-level Java JIT compiler for the Intel Itanium processor. The experiment showed that, compared to the best known algorithm by Govindarajan et al., our IPS algorithm improved the performance by up to +1.8% while it reduced the compilation time for IPS by 58% on average.
2001-01-01 - Speculative precomputation: long-range prefetching of delinquent loads	Recent micro-architectural research has proposed various schemes to enhance processors with additional tags to track various properties of a program. Such a technique, which is usually referred to as information flow tracking, has been widely applied to secure software execution (e.g., taint tracking), protect software privacy and improve performance (e.g., control speculation). In this paper, we propose a novel use of information flow tracking to obfuscate the whole control flow of a program with only modest performance degradation, to defeat malicious code injection, discourage software piracy and impede malware analysis. Specifically, we exploit two common features in information flow tracking: the architectural support for automatic propagation of tags and violation handling of tag misuses. Unlike other schemes that use tags as oracles to catch attacks (e.g., taint tracking) or speculation failures, we use the tags as flow-sensitive predicates to hide normal control flow transfers: the tags are used as predicates for control flow transfers to the violation handler, where the real control flow transfer happens. We have implemented a working prototype based on Itanium processors, by leveraging the hardware support for control speculation. Experimental results show that BOSH can obfuscate the whole control flow with only a mean of 26.7% (ranging from 4% to 59%) overhead on SPECINT2006. The increase in code size and compilation time is also modest.
2001-01-01 - Statistical clock skew modeling with data delay variations	Effective and efficient modelling and management of hardware resources have always been critical toward generating highly efficient code in optimizing compilers. The instruction templates and dispersal rules of the EPIC architecture add new complexity in managing resource constraints to instruction scheduler. We extended a finite state automaton (FSA) approach to efficiently manage all key resource constraints of an EPIC architecture on-the-fly during instruction scheduling. We have fully integrated the FSA-based resource management into the instruction scheduler in the Open Research Compiler for the EPIC architecture. Our integrated approach shows up to 12% speedup on some SPECint2000 benchmarks and 4.5% speedup on average for all SPECint2000 benchmarks on an Itanium machine when compares to an instruction scheduler with decoupled resource management. In the meantime, the instruction scheduling time of our approach is reduced by 4% on average.
2001-01-01 - Register renaming and scheduling for dynamic execution of predicated code	We designed and implemented a software distributed shared memory (DSM) system, SCASH-MPI, by using MPI as the communication layer of the SCASH DSM. With MPI as the communication layer, we could use high-speed networks with several clusters and high portability. Furthermore, SCASH-MPI can use high-speed networks with MPI, which is the most commonly available communication library. On the other hand, existing software DSM systems usually use a dedicated communication layer, TCP, or UDP-Ethernet. SCASH-MPI avoids the need for a large amount of pin-down memory for shared memory use that has limited the applications of the original SCASH. In SCASH-MPI, a thread is created to support remote memory communication using MPI. An experiment on a 4-node Itanium cluster showed that the Laplace Solver benchmark using SCASH-MPI achieves a performance comparable to the original SCASH. Performance degradation is only 6.3% in the NPB BT benchmark Class B test. In SCASH-MPI, page transfer does not start until a page fault is detected. To hide the latency of page transmission, we implemented a prefetch function. The latency in BT Class B was reduced by 64% when the prefetch function was used.
2001-01-01 - Optimizing software data prefetches with rotating registers	MPI derived datatypes are a powerful method to define arbitrary collections of non-contiguous data in memory and to enable non-contiguous data communication in a single MPI function call. In this paper, we employ MPI datatypes in four NAS benchmarks (MG, LU, BT, and SP) to transfer non-contiguous data. Comprehensive performance evaluation was carried out on two clusters: an Itanium-2 Myrinet cluster and a Xeon InfiniBand cluster. Performance results show that using datatypes can achieve performance comparable to manual packing/unpacking in the original benchmarks, though the MPI implementations that were studied also perform internal packing and unpacking on noncontiguous datatype communication. In some cases, better performance can be achieved because of the reduced costs to transfer non-contiguous data. This is because some optimizations in the MPI packing/unpacking implementations can be easily overlooked in manual packing and unpacking by users. Our case study demonstrates that MPI datatypes simplify the implementation of non-contiguous communication and lead to application code with portable performance. We expect that with further improvement of datatype processing and datatype communication such as [10, 24], datatypes can outperform the conventional methods of noncontiguous data communication. Our modified NAS benchmarks can be used to evaluate datatype processing and datatype communication in MPI implementations.
2002-01-01 - On the predictability of program behavior using different input data sets	Compiler-directed data speculation has been implemented on Itanium systems to allow for a compiler to move a load across a store even when the two operations are potentially aliased This not only breaks data dependency to reduce critical path length, but also allows a load to be scheduled far apart from its uses to hide cache miss latencies. However, the effectiveness of data speculation is affected by the sophistication of alias analysis technique as well as the aggressiveness of the instruction scheduler. In general, the more sophisticated is the alias analysis technique, the less performance gain is from data speculation, and the more aggressive is the instruction scheduler, the more opportunity is for data speculation. In this paper we evaluate in various scenarios the performance potentials of data speculation for SPEC2000C benchmarks. For each scenario, we determine the performance contributions of data speculation due to both critical path reduction and cache miss latency reduction. We also show interesting statistics about the effects of scheduling constraints, the percentage of critical dependencies, the impacts of cache miss latencies, and the distances between the load locations before and after data speculation.
2001-01-01 - Memory performance analysis of SPEC2000C for the Intel(R) Itanium/sup TM/ processor	Modern microprocessors incorporate Hardware Counters (HC) that provide useful information with low overhead. HC are not commonly used because of the lack of tools to get their information in an easy way. In this paper, a set of tools to simplify the accessing and programming of Intel Itanium 2 â„¢EARs (Event Address Registers) is presented. The aim of these tools is to characterise the memory accesses of parallel codes, in multicore systems, in which the cache hierarchy can greatly influence the performance. The first tool allows the user to insert in the code, in a simple and transparent way, the instructions needed to monitor and manage hardware counters. Two versions of this tool have been implemented. The first one is a command line tool that takes as input a C source file with appropriate directives and outputs it with the monitoring code added. The other one is a graphical interface that allows the user to select the parts of the code to analise. The second tool takes the information gathered by the monitored parallel code provided by the hardware counters and displays it graphically. This tool shows the information in a comprehensive but simple way, allowing the user to adjust the level of detail. These tools were used to carry out a study of parallel irregular codes. Although this study has been made in a specific environment, the tools here presented can be used in any system as long as it is based on hardware counters present in current processors.
2000-01-01 - High availability and reliability in the itanium processor	This paper introduces a method for improving program run-time performance by gathering work in an application and executing it efficiently in an integrated thread. Our methods extend whole-program optimization by expanding the scope of the compiler through a combination of software thread integration and procedure cloning. In each experiment we integrate a frequently executed procedure with itself twice or thrice, creating two clones. Then, based on profile data we select at compile time the fastest version (original or clone) and modify call sites as needed. We demonstrate our technique by cloning and integrating three procedures from cjpeg and djpeg at the C source code level, compiling with four compilers for the Itanium EPIC architecture and measuring the performance with the on-chip performance measurement units. For cjpeg, which is not significantly constrained by the i-cache, we find integration consistently improves code generated by all compilers but one, with a mean program speedup of 11.99%.
2000-01-01 - Introducing the itanium processors	On machines with high-performance processors, the memory system continues to be a performance bottleneck. Compilers insert prefetch operations and reorder data accesses to improve locality, but increasingly seek to modify an application's data layout to reduce cache miss and page fault penalties. In this paper we discuss Global Variable Layout (GVL), an optimization of the placement of entire static global data objects in the binary. We describe two practical methods for GVL in the HP-UX Integrity optimizing compiler for the Itanium Â© architecture. The first layout strategy relies on profile feedback, collaboratively employing the compiler, the linker and a pre-link tool to facilitate reordering. The second strategy uses whole-program analysis to drive data layout decisions, and does not require the use of a dynamic profile. We give a detailed description of our implementation and evaluate its performance for the SPEC integer benchmark programs, as well as for a large commercial database application.
2000-01-01 - The AzusA 16-way itanium server	In this paper we demonstrate that effective structure optimization is essential to improve code quality and reduce compilation overhead for object-oriented programs. We propose to address this problem by using an effective representation of structure operation, folding indirect memory accesses to structure fields, flattening structures judiciously, and allowing more aggressive procedure inlining. These techniques enable the existing scalar optimizations, which were well tuned for the traditional imperative languages, to work effectively on object-oriented programs, allowing them to make better use of the performance enhancing-features available on modern processors. We have implemented this strategy in an SSA based global optimization framework in the Open Research Compiler, targeting the Itanium Processor Family. The experimental results with representative C++ benchmarks show that the applications' performance can be improved significantly. For instance, Eon's performance is improved by 35.6%, while the execution time of the Stepanov benchmark is reduced by a factor of 24.
2001-01-01 - Performance characteristics of Itanium/sup TM/ processor on data encryption algorithms	With the recent introduction of Itanium Processor Family (IPF) microprocessors for enterprise servers it is imperative to understand the behavior of server class applications. This paper analyzes the behavior of the Oracle Database Benchmark (ODB), an online transaction processing (OLTP) workload, and compares it with SPEC CPU2000. This study examines code mix, instruction and data supply, and value locality. The results show that while IPF's bundle constraints cause a large injection of NOPs into the code stream, IPFs register stack engine successfully reduces the number of memory operations by nearly 50%. The control-flow predictability of ODB is better than CPU2000, in spite of ODB's large active branch footprint. Due to ODB's large memory footprint, cache misses (particularly instruction cache misses) are a much more serious problem than in CPU2000.
2000-01-01 - Itanium processor microarchitecture	The goal of the Linuxâ„¢ Standard Base (LSB) is to develop and promote a set of standards that will increase compatibility among Linux distributions and enable software applications to run on any compliant Linux system. There are currently LSB specifications available for the Intel Architecture IA-32â„¢ processors and for the 32- and 64-bit PowerPCâ„¢, Itaniumâ„¢, 31- and 64-bit zSeriesâ„¢, and AMD64â„¢ architectures. This paper describes the process of building LSB-compliant applications, and covers the use of the LSB development environments, testing of binaries, and packaging.
2001-01-01 - The impact of If-conversion and branch prediction on program execution on the Intel/sup R/ Itanium/sup TM/ processor	Includes: (1) Europe's Cellulars To Share Infrastructure? (2) Why the Fuss About 3G? (3) Senate Changes Will Shake Telecom, Defense R&D, Energy. (4) In Energy, Will Bingaman Out-Cheney Cheney? (5) India's Power Grid Finds Helping Hand. (6) The Itanium Platform Lands Its First Computing Systems. (7) Ion Beam Keeps Liquid Crystals in Line. (8) How to Raise UV Nanolasers. (9) Swedish Start-Up Puts New Spin on Pen and Paper. (10) Big Welcome for MIT's Web-Based Courseware.
2000-01-01 - The 82460GX server/workstation chip set	Summary form only given. Moore's law has been the guiding principle of silicon CMOS technology scaling for four decades. Transistor density has been doubled every two years in Intel microprocessors since early 70. Intel's latest dual core ItaniumÂ® 2 server chip has deployed 1.72 billion transistors vs. 2,250 transistors in the 4004 processor introduced in 1971. Same density improvement trends can be found in memory and other ASIC products as well. The remarkable progress in packing more functionality, complexity, and performance into a single silicon chip could have not been achieved without numerous innovations in IC manufacturing technologies, lithography, transistors, interconnects and packaging. In this presentation, the author provides a review of most critical process technology innovations in the last decade, including advanced lithography, strained silicon transistors, high k/metal gate transistors, Cu metallization, and low k ILD. The last decade of Moore's law has been characterized by significant differences, compared to the first three decades of silicon scaling, in the types of technical challenges and innovations that are required to advance Moore's law. The insight into the challenges and opportunities will help guide advancing Moore's law into the future.
2000-01-01 - Devices and circuits [Technology 2000 analysis and forecast]	Analyst predicts $1.4B iPhone windfall, Sun donates cluster code, Asia leads in mobile TV, Intel Itanium headed for 65 nm, and more.
2001-01-01 - Debug methodology for the McKinley processor	Chip makers are designing a new generation of microprocessors to stop buffer overflow assaults, exploits that hackers often use to attack and extract data from PCs or servers. AMD's Athlon-64 chips for notebook and desktop computers and its Opteron processors for servers include features that provide buffer-overflow protection. Intel offers buffer-overflow protection in its Itanium chips for servers. A buffer overflow occurs when a program or process tries to store more data in a buffer than it was designed to hold. Operating systems that support the buffer-overflow prevention approach mark certain data in memory with a bit that identifies them as executable or nonexecutable. The AMD chips let users turn off the new security feature for legacy programs not written to work with the technology so that the applications can continue to function.
2001-01-01 - Test methodology for the McKinley processor	In this issue, Tools and Products features information about dnp denmark's SuperNova Screen, JVC's HDTVs, Intel's Itanium 2 processors, Curtiss-Wright's Atlast PMC/1D, InterWrite's Meeting Pad 400, Bauhaus' Mirage Nomad, Natual Motion's endorphin, Solidworks' eDrawings, Prefuse, and Cave UT 2004 v1.1.
